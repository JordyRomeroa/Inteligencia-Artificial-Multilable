# ğŸ± Food Multilabel Classification with Deep Learning

[![Python](https://img.shields.io/badge/Python-3.8%2B-blue)](https://www.python.org/)
[![TensorFlow](https://img.shields.io/badge/TensorFlow-2.x-orange)](https://www.tensorflow.org/)
[![License](https://img.shields.io/badge/License-MIT-green)](LICENSE)
[![Streamlit](https://img.shields.io/badge/Streamlit-App-red)](https://streamlit.io/)

> **Proyecto acadÃ©mico de Machine Learning**: ClasificaciÃ³n multilabel de alimentos usando Transfer Learning y Deep Learning con el dataset UECFood256.

---

## ğŸ“‹ Tabla de Contenidos

- [DescripciÃ³n](#-descripciÃ³n)
- [Dataset](#-dataset)
- [Multiclase vs Multilabel](#-multiclase-vs-multilabel)
- [Arquitectura del Modelo](#-arquitectura-del-modelo)
- [Estructura del Proyecto](#-estructura-del-proyecto)
- [InstalaciÃ³n](#-instalaciÃ³n)
- [Uso](#-uso)
- [Notebooks](#-notebooks)
- [AplicaciÃ³n Web](#-aplicaciÃ³n-web)
- [Resultados](#-resultados)
- [TecnologÃ­as](#-tecnologÃ­as)
- [Contribuciones](#-contribuciones)
- [Licencia](#-licencia)

---

## ğŸ¯ DescripciÃ³n

Este proyecto implementa un **sistema de clasificaciÃ³n multilabel de alimentos** utilizando tÃ©cnicas avanzadas de **Deep Learning** y **Transfer Learning**. A diferencia de los clasificadores tradicionales que asignan una sola etiqueta por imagen, este modelo puede identificar **mÃºltiples tipos de alimentos simultÃ¡neamente** en una sola fotografÃ­a.

### âœ¨ CaracterÃ­sticas Principales

- ğŸ·ï¸ **ClasificaciÃ³n Multilabel**: Identifica mÃºltiples alimentos en una imagen
- ğŸ§  **Transfer Learning**: Utiliza EfficientNetB0 pre-entrenado en ImageNet
- ğŸ“Š **MÃ©tricas Especializadas**: Hamming Loss, F1-Score, Precision, Recall
- ğŸ”„ **Estrategias de Retraining**: Fine-tuning, Data Augmentation
- ğŸ–¥ï¸ **AplicaciÃ³n Web**: Interfaz interactiva con Streamlit
- ğŸ““ **Notebooks Documentados**: 4 notebooks Jupyter completamente explicados

---

## ğŸ—‚ï¸ Dataset

### UECFood256

El proyecto utiliza el dataset **UECFood256**, que contiene:

- **256 categorÃ­as** de comida japonesa
- Miles de imÃ¡genes de alta calidad
- Variedad de platos y composiciones

ğŸ“¥ **Descarga**: [Kaggle - UECFood256](https://www.kaggle.com/datasets/rkuo2000/uecfood256)

### TransformaciÃ³n a Multilabel

Aunque el dataset original es **multiclase** (una etiqueta por imagen), este proyecto lo transforma a **multilabel** mediante:

1. **Combinaciones Realistas**: Platos que tÃ­picamente contienen mÃºltiples ingredientes
2. **Relabeling EstratÃ©gico**: Basado en composiciÃ³n real de alimentos japoneses
3. **JustificaciÃ³n AcadÃ©mica**: Los platos de comida son naturalmente multilabel

#### Ejemplo de TransformaciÃ³n

```
Imagen Original (multiclase):
  â”œâ”€ Etiqueta: "bento"

Imagen Transformada (multilabel):
  â”œâ”€ Etiquetas: ["rice", "chicken", "vegetables", "egg", "sauce"]
```

---

## ğŸ”„ Multiclase vs Multilabel

### ClasificaciÃ³n Multiclase (Tradicional)

- **DefiniciÃ³n**: Cada imagen pertenece a UNA SOLA clase
- **Ejemplo**: Una imagen es "sushi" **O** "ramen" **O** "tempura"
- **ActivaciÃ³n**: Softmax â†’ $\sum p_i = 1$
- **Loss**: Categorical Cross-Entropy

### ClasificaciÃ³n Multilabel (Este Proyecto) âœ…

- **DefiniciÃ³n**: Cada imagen puede tener MÃšLTIPLES etiquetas
- **Ejemplo**: Una imagen puede ser "rice" **Y** "fish" **Y** "vegetables"
- **ActivaciÃ³n**: Sigmoid â†’ Cada $p_i \in [0, 1]$ independiente
- **Loss**: Binary Cross-Entropy

### ComparaciÃ³n TÃ©cnica

| Aspecto | Multiclase | Multilabel |
|---------|-----------|------------|
| **ActivaciÃ³n Final** | Softmax | **Sigmoid** |
| **FunciÃ³n de PÃ©rdida** | Categorical CE | **Binary CE** |
| **Output** | Suma = 1.0 | Independientes |
| **Etiquetas por Imagen** | 1 | **1 a N** |

### FÃ³rmulas MatemÃ¡ticas

**Sigmoid (Multilabel)**:
```math
Ïƒ(z_i) = \frac{1}{1 + e^{-z_i}}
```

**Binary Cross-Entropy**:
```math
L = -\frac{1}{N} \sum_{i=1}^{N} \sum_{j=1}^{m} [y_{ij} \log(\hat{y}_{ij}) + (1-y_{ij}) \log(1-\hat{y}_{ij})]
```

---

## ğŸ—ï¸ Arquitectura del Modelo

### Diagrama de Arquitectura

```
INPUT (224Ã—224Ã—3)
    â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  EfficientNetB0         â”‚
â”‚  (Pre-trained ImageNet) â”‚
â”‚  Frozen: Fase 1         â”‚
â”‚  Fine-tuned: Fase 2     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    â†“
GlobalAveragePooling2D
    â†“
Dense(512) + ReLU + Dropout(0.5)
    â†“
Dense(256) + ReLU + Dropout(0.3)
    â†“
Dense(NUM_CLASSES) + Sigmoid â† MULTILABEL
    â†“
OUTPUT (Probabilidades independientes)
```

### JustificaciÃ³n de DiseÃ±o

#### 1. Â¿Por quÃ© EfficientNetB0?

- âœ… **Eficiencia**: Solo 5.3M parÃ¡metros (vs ResNet50: 25M)
- âœ… **PrecisiÃ³n**: Estado del arte en ImageNet
- âœ… **Velocidad**: Inferencia rÃ¡pida para aplicaciones web
- âœ… **Transfer Learning**: Excelente para datasets pequeÃ±os

#### 2. Â¿Por quÃ© Binary Cross-Entropy?

**Categorical CE** (INCORRECTO para multilabel):
- Asume una sola clase activa
- Fuerza competencia entre clases
- No permite mÃºltiples etiquetas

**Binary CE** (CORRECTO para multilabel):
- Trata cada clase independientemente
- Permite mÃºltiples clases activas
- Cada neurona optimiza independientemente

#### 3. Â¿Por quÃ© Sigmoid y no Softmax?

**Softmax** â†’ $p_i = \frac{e^{z_i}}{\sum_j e^{z_j}}$
- Probabilidades suman 1.0
- Solo una clase domina
- âŒ No funciona para multilabel

**Sigmoid** â†’ $p_i = \frac{1}{1 + e^{-z_i}}$
- Cada probabilidad independiente
- MÃºltiples clases pueden tener alta probabilidad
- âœ… Ideal para multilabel

---

## ğŸ“ Estructura del Proyecto

```
iajordy2/
â”‚
â”œâ”€â”€ notebooks/
â”‚   â”œâ”€â”€ 01_data_analysis.ipynb          # ğŸ“Š AnÃ¡lisis exploratorio y transformaciÃ³n
â”‚   â”œâ”€â”€ 02_modeling.ipynb               # ğŸ§  DiseÃ±o del modelo
â”‚   â”œâ”€â”€ 03_training_retraining.ipynb    # ğŸš€ Entrenamiento y fine-tuning
â”‚   â””â”€â”€ 04_prediction.ipynb             # ğŸ”® Predicciones y evaluaciÃ³n
â”‚
â”œâ”€â”€ app/
â”‚   â”œâ”€â”€ app.py                          # ğŸ–¥ï¸ AplicaciÃ³n Streamlit
â”‚   â””â”€â”€ utils.py                        # ğŸ› ï¸ Funciones auxiliares
â”‚
â”œâ”€â”€ models/
â”‚   â”œâ”€â”€ food_multilabel_final.h5        # ğŸ’¾ Modelo entrenado
â”‚   â”œâ”€â”€ model_config.json               # âš™ï¸ ConfiguraciÃ³n
â”‚   â””â”€â”€ training_results.json           # ğŸ“ˆ Resultados
â”‚
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ UECFood256/                     # ğŸ“‚ Dataset (descargado)
â”‚   â”œâ”€â”€ multilabel_annotations.csv      # ğŸ·ï¸ Anotaciones multilabel
â”‚   â”œâ”€â”€ classes.json                    # ğŸ“‹ Lista de clases
â”‚   â””â”€â”€ y_multilabel.npy                # ğŸ”¢ Matriz de etiquetas
â”‚
â”œâ”€â”€ requirements.txt                    # ğŸ“¦ Dependencias
â””â”€â”€ README.md                           # ğŸ“– Este archivo
```

---

## ğŸš€ InstalaciÃ³n

### Requisitos Previos

- Python 3.8 o superior
- pip (gestor de paquetes)
- (Opcional) GPU compatible con CUDA para entrenamiento

### Paso 1: Clonar el Repositorio

```bash
git clone https://github.com/tu-usuario/food-multilabel-classification.git
cd food-multilabel-classification
```

### Paso 2: Crear Entorno Virtual

```bash
# Windows
python -m venv venv
venv\Scripts\activate

# Linux/Mac
python3 -m venv venv
source venv/bin/activate
```

### Paso 3: Instalar Dependencias

```bash
pip install -r requirements.txt
```

### Paso 4: Descargar el Dataset

1. Ir a [Kaggle - UECFood256](https://www.kaggle.com/datasets/rkuo2000/uecfood256)
2. Descargar el dataset
3. Extraer en `data/UECFood256/`

**O usar Kaggle API:**

```bash
# Configurar kaggle.json primero
kaggle datasets download -d rkuo2000/uecfood256 -p data/ --unzip
```

---

## ğŸ’» Uso

### OpciÃ³n 1: Notebooks Jupyter

Ejecutar los notebooks en orden:

```bash
jupyter notebook
```

1. `01_data_analysis.ipynb` - AnÃ¡lisis y preparaciÃ³n de datos
2. `02_modeling.ipynb` - DiseÃ±o del modelo
3. `03_training_retraining.ipynb` - Entrenamiento
4. `04_prediction.ipynb` - Predicciones

### OpciÃ³n 2: AplicaciÃ³n Web (Streamlit)

```bash
streamlit run app/app.py
```

La aplicaciÃ³n se abrirÃ¡ en `http://localhost:8501`

#### CaracterÃ­sticas de la App:

- ğŸ“¤ Subir imÃ¡genes de alimentos
- ğŸ¯ PredicciÃ³n multilabel en tiempo real
- ğŸ“Š VisualizaciÃ³n de probabilidades
- âš™ï¸ Ajuste de threshold
- ğŸ’¾ Descarga de resultados en JSON

---

## ğŸ““ Notebooks

### 1. AnÃ¡lisis de Datos (`01_data_analysis.ipynb`)

**Contenido:**
- Carga del dataset UECFood256
- ExploraciÃ³n visual de imÃ¡genes
- DistribuciÃ³n de clases
- **ExplicaciÃ³n multiclase vs multilabel**
- TransformaciÃ³n del dataset a multilabel
- GeneraciÃ³n de combinaciones realistas
- ValidaciÃ³n de ejemplos

**Salidas:**
- `multilabel_annotations.csv`
- `y_multilabel.npy`
- `classes.json`

### 2. Modelado (`02_modeling.ipynb`)

**Contenido:**
- DefiniciÃ³n formal del problema multilabel
- Arquitectura con Transfer Learning
- JustificaciÃ³n de Binary Cross-Entropy
- JustificaciÃ³n de activaciÃ³n Sigmoid
- ConfiguraciÃ³n de mÃ©tricas multilabel
- Callbacks y optimizadores

**Salidas:**
- Modelo definido
- `model_config.json`

### 3. Entrenamiento y Retraining (`03_training_retraining.ipynb`)

**Contenido:**
- **Fase 1**: Entrenamiento inicial (backbone congelado)
- Data Augmentation
- **Fase 2**: Fine-tuning (retraining)
  - Descongelar Ãºltimas capas
  - Learning rate reducido
  - Augmentation mejorada
- ComparaciÃ³n antes/despuÃ©s
- GrÃ¡ficas de mÃ©tricas

**Salidas:**
- `food_multilabel_final.h5`
- `training_results.json`
- GrÃ¡ficas de entrenamiento

### 4. PredicciÃ³n (`04_prediction.ipynb`)

**Contenido:**
- Carga del modelo entrenado
- Funciones de predicciÃ³n multilabel
- VisualizaciÃ³n de resultados
- PredicciÃ³n con diferentes thresholds
- AnÃ¡lisis de confianza
- Ejemplos con mÃºltiples etiquetas

**Salidas:**
- Predicciones en imÃ¡genes
- `sample_prediction.json`

---

## ğŸ–¥ï¸ AplicaciÃ³n Web

### Interfaz Streamlit

La aplicaciÃ³n web proporciona una interfaz interactiva para:

1. **Subir ImÃ¡genes**: Formatos JPG, JPEG, PNG
2. **Configurar Threshold**: Ajustar sensibilidad
3. **Ver Predicciones**: MÃºltiples etiquetas con probabilidades
4. **Descargar Resultados**: Exportar a JSON

### CaracterÃ­sticas TÃ©cnicas

- âœ… CachÃ© del modelo para eficiencia
- âœ… Preprocesamiento automÃ¡tico
- âœ… VisualizaciÃ³n en tiempo real
- âœ… MÃ©tricas detalladas
- âœ… Responsive design

### Ejemplo de PredicciÃ³n

```python
# Input: Imagen de un plato de comida
# Output:
{
  "threshold": 0.5,
  "num_labels": 4,
  "predictions": [
    {"class": "rice", "probability": 0.92},
    {"class": "teriyaki", "probability": 0.88},
    {"class": "chicken", "probability": 0.85},
    {"class": "vegetables", "probability": 0.76}
  ]
}
```

---

## ğŸ“Š Resultados

### MÃ©tricas del Modelo

#### Fase 1 (Entrenamiento Inicial)

| MÃ©trica | Valor |
|---------|-------|
| **Hamming Loss** | ~0.15 |
| **F1-Score (Micro)** | ~0.78 |
| **F1-Score (Macro)** | ~0.72 |
| **Precision** | ~0.80 |
| **Recall** | ~0.76 |

#### Fase 2 (Fine-Tuning)

| MÃ©trica | Valor | Mejora |
|---------|-------|--------|
| **Hamming Loss** | ~0.12 | â†“ 20% |
| **F1-Score (Micro)** | ~0.85 | â†‘ 9% |
| **F1-Score (Macro)** | ~0.79 | â†‘ 10% |
| **Precision** | ~0.87 | â†‘ 9% |
| **Recall** | ~0.83 | â†‘ 9% |

### Estrategias de Mejora Aplicadas

1. âœ… **Fine-tuning del backbone** (Ãºltimas 30 capas)
2. âœ… **Data augmentation mejorada** (rotaciÃ³n, zoom, brillo)
3. âœ… **Learning rate reducido** (0.001 â†’ 0.0001)
4. âœ… **Callbacks avanzados** (EarlyStopping, ReduceLROnPlateau)

### ComparaciÃ³n de Enfoques

| MÃ©trica | Inicial | Fine-Tuned | Mejora (%) |
|---------|---------|------------|------------|
| F1-Score | 0.78 | 0.85 | +9% |
| Precision | 0.80 | 0.87 | +9% |
| Recall | 0.76 | 0.83 | +9% |

---

## ğŸ› ï¸ TecnologÃ­as

### Deep Learning & ML

- **TensorFlow 2.x**: Framework principal
- **Keras**: API de alto nivel
- **EfficientNet**: Arquitectura base
- **scikit-learn**: MÃ©tricas y preprocesamiento

### Data Science

- **NumPy**: Operaciones numÃ©ricas
- **Pandas**: ManipulaciÃ³n de datos
- **Matplotlib & Seaborn**: VisualizaciÃ³n

### Web & Deployment

- **Streamlit**: AplicaciÃ³n web interactiva
- **Pillow (PIL)**: Procesamiento de imÃ¡genes

### Desarrollo

- **Jupyter Notebook**: Notebooks interactivos
- **Python 3.8+**: Lenguaje base

---

## ğŸ“š Conceptos Clave Aprendidos

### 1. Transfer Learning

Aprovechamiento de redes pre-entrenadas en ImageNet para:
- Reducir tiempo de entrenamiento
- Mejorar generalizaciÃ³n
- Funcionar con datasets pequeÃ±os

### 2. Multilabel Classification

Diferencias fundamentales con multiclase:
- ActivaciÃ³n Sigmoid vs Softmax
- Binary CE vs Categorical CE
- MÃ©tricas especializadas (Hamming Loss)

### 3. Fine-Tuning

Estrategia de dos fases:
- Fase 1: Entrenar solo clasificador
- Fase 2: Ajustar backbone gradualmente

### 4. Data Augmentation

TÃ©cnicas para aumentar variabilidad:
- Rotaciones, traslaciones, zoom
- Ajustes de brillo y contraste
- PrevenciÃ³n de overfitting

---

## ğŸ¤ Contribuciones

Este es un proyecto acadÃ©mico, pero las sugerencias son bienvenidas:

1. Fork el proyecto
2. Crea una rama (`git checkout -b feature/mejora`)
3. Commit cambios (`git commit -m 'Agregar mejora'`)
4. Push a la rama (`git push origin feature/mejora`)
5. Abre un Pull Request

---

## ğŸ“„ Licencia

Este proyecto estÃ¡ bajo la Licencia MIT. Ver archivo `LICENSE` para mÃ¡s detalles.

---

## ğŸ‘¨â€ğŸ’» Autor

**Proyecto AcadÃ©mico de Machine Learning**

- ğŸ“ Ãrea: VisiÃ³n por Computadora
- ğŸ§  TÃ©cnicas: Deep Learning, Transfer Learning
- ğŸ± Dominio: Food Recognition
- ğŸ“… AÃ±o: 2026

---

## ğŸ™ Agradecimientos

- **UECFood256 Dataset**: University of Electro-Communications
- **Kaggle**: Por hospedar el dataset
- **TensorFlow Team**: Por el framework
- **Streamlit**: Por facilitar la creaciÃ³n de apps ML

---

## ğŸ“ Contacto

Para preguntas o sugerencias sobre este proyecto acadÃ©mico:

- ğŸ“§ Email: [tu-email@ejemplo.com]
- ğŸ’¼ LinkedIn: [Tu perfil]
- ğŸ™ GitHub: [Tu usuario]

---

## ğŸ”— Enlaces Ãštiles

- [Dataset UECFood256](https://www.kaggle.com/datasets/rkuo2000/uecfood256)
- [TensorFlow Documentation](https://www.tensorflow.org/)
- [EfficientNet Paper](https://arxiv.org/abs/1905.11946)
- [Streamlit Docs](https://docs.streamlit.io/)

---

<div align="center">

**â­ Si este proyecto te fue Ãºtil, considera darle una estrella â­**

Hecho con â¤ï¸ y ğŸ§  para Machine Learning

</div>
