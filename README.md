Aquí tienes el archivo completo en un único bloque de código para que puedas copiarlo y pegarlo directamente en tu `README.md`.

```md
# YOLO 3-Class Object Detection with MLflow

A robust YOLOv8 detection system specialized for **Person, Car, and Dog** classes. This project implements a complete MLOps pipeline featuring **MLflow** for experiment tracking and model registry, alongside a production-ready **Flask API** for inference.

## Stack

- **YOLOv8** (Ultralytics) - State-of-the-art object detection model using transfer learning from COCO weights.
- **MLflow** - End-to-end lifecycle management: Experiment tracking, metrics logging, and Model Registry.
- **Pascal VOC 2012** - Benchmark dataset filtered specifically for the target classes (person, car, dog).
- **Flask** - Lightweight REST API for serving model predictions.
- **PyTorch** (CUDA 12.1) - Deep learning framework with GPU acceleration support.

## Structure

The project separates the training pipeline (notebooks) from the deployment application (app).

```text
iajordy2/
├── notebooks/                # Complete ML pipeline & experiments
│   ├── 01_dataset_validation.ipynb  # Data integrity & class distribution checks
│   ├── 02_train_yolo.ipynb          # Initial exploratory training
│   ├── 03_training.ipynb            # Main training loop with MLflow integration
│   ├── 04_prediction.ipynb          # Inference testing on static images
│   └── 05_retrain_improved.ipynb    # Optimized training (Targeting 'Dog' class)
├── app/                      # Flask API application
│   ├── mlflow_utils.py              # Custom MLflowYOLOTracker class
│   ├── api.py / inference_api.py    # Main API endpoints
│   ├── run_server.py                # Server entry point
│   └── templates/ static/           # Web interface assets
├── data/                     # Dataset storage
│   ├── VOCdevkit/                   # Original Pascal VOC data
│   ├── data.yaml                    # YOLO configuration file
│   ├── images/                      # Split: train/val/test
│   └── labels/                      # Annotations in YOLO format
├── models/                   # Local storage for trained weights (.pt)
├── runs/mlflow/              # Local MLflow tracking store
└── requirements.txt          # Python dependencies

```

## Setup

**Requirements**: Python 3.9+, CUDA 12.1 compatible GPU, 8GB+ RAM.

```bash
# 1. Create virtual environment
python -m venv .venv

# 2. Activate environment (Windows)
.venv\Scripts\activate
# (Linux/Mac: source .venv/bin/activate)

# 3. Install dependencies
pip install -r requirements.txt

# 4. Prepare dataset (Download & Filter Pascal VOC)
python prepare_dataset.py

```

## Training

The training workflow is split into a standard baseline and an optimized version using advanced augmentation.

**Standard Training (Notebook 03)**
Establishes a baseline using YOLOv8 Nano.

```bash
# Execution Flow:
# Run cells: Cell 2 → Cell 4 → Cell 6 → Cell 8
# Output: models/best.pt
# MLflow experiment: yolo_3class_detection

```

**Optimized Training (Notebook 05)**
Improves performance, specifically for the "Dog" class, using hyperparameter tuning.

```bash
# Execution Flow:
# Run cells: Cell 2 → Cell 5 → Cell 16 → Cell 17 → Cell 19
# Output: models/best_improved.pt + MLflow Model Registry
# Optimizations: Copy-Paste augmentation, Mixup, NMS tuning
# MLflow experiment: yolo_improved_training

```

### Model Path Convention

All notebooks strictly follow this **single-path convention**:

* **Base model**: `models/best.pt` (Generated by notebooks 02, 03, 04)
* **Improved model**: `models/best_improved.pt` (Generated by notebook 05)
* **MLflow artifacts**: All models are also logged remotely to `artifact_path='model'` (singular).

## MLflow

MLflow tracks metrics and artifacts for every run.

**Start UI**
Replace the URI path with your absolute path to the `runs/mlflow` directory.

```bash
python -m mlflow ui --backend-store-uri "file:///C:/Users/jordy/OneDrive/Desktop/iaaaa/iajordy2/runs/mlflow" --port 5001

```

→ Access dashboard at: http://localhost:5001

**Tracked Metrics**: `mAP50`, `mAP50-95`, `precision`, `recall`, and per-class AP.
**Artifacts**: The trained model (`.pt`), learning curves (`results.png`), confusion matrices, and validation batches.
**Model Registry**: Best models are registered via `mlflow.register_model()` for version control.

**MLflowYOLOTracker** (`app/mlflow_utils.py`)
A custom wrapper to bridge YOLOv8 and MLflow:

* `setup_mlflow()` - Initialize backend store and set active experiment.
* `log_training_params()` - Log YOLO hyperparameters (epochs, batch, lr).
* `log_metrics_from_yolo()` - Parse `results.csv` to log metrics step-by-step.
* `log_training_artifacts()` - Upload output plots and weights to the artifact store.

## API Endpoints

**Start server** (ensure a model exists in `models/`)

```bash
cd app
python run_server.py

```

→ Access API at: http://localhost:5000

| Method | Endpoint | Description |
| --- | --- | --- |
| **POST** | `/predict` | Upload an image to receive JSON detections. |
| **POST** | `/api/model/retrain` | Trigger a manual background retraining process. |
| **GET** | `/api/model/info` | Get current model version, experiment ID, and metrics. |

## Training Config

Detailed configuration for the experiments conducted.

**Standard (Notebook 03)**

* **Model**: YOLOv8n (Nano)
* **Epochs**: 50
* **Batch Size**: 16, **Img Size**: 640
* **Optimizer**: AdamW (`lr=0.001`)
* **Augmentation**: Basic (HSV, degrees, translate, scale)

**Optimized (Notebook 05)**

* **Model**: YOLOv8s (Small)
* **Epochs**: 100
* **Batch Size**: 8, **Img Size**: 640
* **Optimizer**: AdamW (`lr=0.001`)
* **Advanced Aug**: `copy-paste=0.3` (Critical for Dog class), `mixup=0.15`
* **NMS**: `IoU=0.5`, `conf=0.15` (Tuned for overlapping objects)
* **Target**: Dog AP50 → **0.65+** (Improved from baseline 0.468)

## Expected Performance

Target metrics based on validation set evaluation:

* **Overall mAP50**: 0.70+
* **Person AP50**: 0.85+
* **Car AP50**: 0.75+
* **Dog AP50**: 0.65+ (Optimized for multi-object groups and occlusions)

## Workflow

1. **Dataset validation**: Run [01_dataset_validation.ipynb](https://www.google.com/search?q=notebooks/01_dataset_validation.ipynb) to verify data integrity.
2. **Initial training**: Execute [03_training.ipynb](https://www.google.com/search?q=notebooks/03_training.ipynb) to establish a baseline.
3. **Optimization**: Use [05_retrain_improved.ipynb](https://www.google.com/search?q=notebooks/05_retrain_improved.ipynb) to apply advanced augmentation.
4. **Deployment**: Start the API server with `python run_server.py`.
5. **Monitoring**: View and compare runs in the MLflow UI.

## Troubleshooting

* **CUDA OOM**: Reduce `batch_size` (e.g., to 4) or switch back to `YOLOv8n`.
* **MLflow UI fails**: Ensure the `--backend-store-uri` points to a valid absolute path containing the `mlruns` or `runs/mlflow` folder.
* **Model not found**: The API looks for `models/best.pt` or `models/best_improved.pt`. Verify training completed successfully.
* **Low accuracy**: Increase epochs (150+), or further tune `copy-paste` and `mixup` probabilities.

## Technical Notes

* **YOLO Outputs**: Training logs saved to `runs/train/`, validation predictions to `runs/detect/`.
* **MLflow Backend**: Uses a local file-based store at `runs/mlflow/`.
* **Model Registry**: Allows versioning of models (e.g., Production vs Staging).
* **Determinism**: `deterministic=True` enabled in YOLO settings for reproducibility.
* **Hardware**: Auto-detects CUDA. If unavailable, falls back to CPU (slower).

## Requirements

* **OS**: Windows 10/11, Linux, macOS
* **GPU**: NVIDIA 4GB+ VRAM (RTX 3060/3080 recommended)
* **RAM**: 8GB minimum, 16GB recommended
* **Storage**: ~10GB (Dataset + Models)
* **Python**: 3.9+

---

