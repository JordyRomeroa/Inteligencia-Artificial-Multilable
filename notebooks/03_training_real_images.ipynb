{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0de0cc12",
   "metadata": {},
   "source": [
    "# Entrenamiento Multilabel con PASCAL VOC 2007"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5f96431d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow version: 2.20.0\n",
      "GPU disponible: False\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import json\n",
    "from pathlib import Path\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers, models, optimizers\n",
    "from tensorflow.keras.applications import EfficientNetB0\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import hamming_loss, f1_score, precision_score, recall_score, accuracy_score\n",
    "\n",
    "print(f\"TensorFlow version: {tf.__version__}\")\n",
    "print(f\"GPU disponible: {len(tf.config.list_physical_devices('GPU')) > 0}\")\n",
    "\n",
    "SEED = 42\n",
    "np.random.seed(SEED)\n",
    "tf.random.set_seed(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dbd8430e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Configuracion:\n",
      "  Tamaño imagen: (224, 224)\n",
      "  Batch size: 16\n",
      "  Epocas inicial: 30\n",
      "  Epocas fine-tuning: 40\n"
     ]
    }
   ],
   "source": [
    "PROJECT_ROOT = Path(os.getcwd()).parent\n",
    "DATA_DIR = PROJECT_ROOT / 'data' / 'voc2007'\n",
    "MODELS_DIR = PROJECT_ROOT / 'models'\n",
    "MODELS_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "IMG_SIZE = (224, 224)\n",
    "BATCH_SIZE = 16\n",
    "INITIAL_EPOCHS = 30\n",
    "FINETUNING_EPOCHS = 40\n",
    "LEARNING_RATE_INITIAL = 0.0005\n",
    "LEARNING_RATE_FINETUNING = 0.00005\n",
    "\n",
    "print(f\"Configuracion:\")\n",
    "print(f\"  Tamaño imagen: {IMG_SIZE}\")\n",
    "print(f\"  Batch size: {BATCH_SIZE}\")\n",
    "print(f\"  Epocas inicial: {INITIAL_EPOCHS}\")\n",
    "print(f\"  Epocas fine-tuning: {FINETUNING_EPOCHS}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8060b57a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cargando desde: c:\\Users\\mlata\\Documents\\iajordy2\\data\\voc2007\n",
      "Clases cargadas: 20\n",
      "Primeras 10 clases: ['aeroplane', 'bicycle', 'bird', 'boat', 'bottle', 'bus', 'car', 'cat', 'chair', 'cow']\n"
     ]
    }
   ],
   "source": [
    "print(f\"Cargando desde: {DATA_DIR}\")\n",
    "\n",
    "with open(DATA_DIR / 'classes.json', 'r') as f:\n",
    "    classes = json.load(f)\n",
    "\n",
    "NUM_CLASSES = len(classes)\n",
    "\n",
    "print(f\"Clases cargadas: {NUM_CLASSES}\")\n",
    "print(f\"Primeras 10 clases: {classes[:10]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ac471230",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cargando dataset PASCAL VOC 2007 desde NPZ...\n",
      "Imagenes cargadas: (2501, 224, 224, 3)\n",
      "Labels cargados: (2501, 20)\n",
      "Clases por imagen (promedio): 1.61\n",
      "Imagenes normalizadas a rango [0, 1]\n"
     ]
    }
   ],
   "source": [
    "print(\"Cargando dataset PASCAL VOC 2007 desde NPZ...\")\n",
    "\n",
    "# Cargar NPZ\n",
    "npz_file = DATA_DIR / 'voc2007_multilabel.npz'\n",
    "if not npz_file.exists():\n",
    "    raise FileNotFoundError(f\"No se encuentra {npz_file}. Ejecuta primero 01_data_analysis.ipynb\")\n",
    "\n",
    "data = np.load(npz_file)\n",
    "images = data['images']\n",
    "labels = data['labels']\n",
    "\n",
    "print(f\"Imagenes cargadas: {images.shape}\")\n",
    "print(f\"Labels cargados: {labels.shape}\")\n",
    "print(f\"Clases por imagen (promedio): {labels.sum(axis=1).mean():.2f}\")\n",
    "\n",
    "# Normalizar imagenes a [0, 1]\n",
    "images = images.astype(np.float32) / 255.0\n",
    "\n",
    "print(f\"Imagenes normalizadas a rango [0, 1]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "167c4963",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: 1750 imágenes\n",
      "Val: 375 imágenes\n",
      "Test: 376 imágenes\n",
      "Train labels: 1.62 categorías/imagen\n",
      "Test labels: 1.59 categorías/imagen\n",
      "Val labels: 1.57 categorías/imagen\n"
     ]
    }
   ],
   "source": [
    "X_train, X_temp, y_train, y_temp = train_test_split(\n",
    "    images, labels, test_size=0.3, random_state=SEED\n",
    ")\n",
    "X_val, X_test, y_val, y_test = train_test_split(\n",
    "    X_temp, y_temp, test_size=0.5, random_state=SEED\n",
    ")\n",
    "\n",
    "print(f\"Train: {len(X_train)} imágenes\")\n",
    "print(f\"Val: {len(X_val)} imágenes\")\n",
    "print(f\"Test: {len(X_test)} imágenes\")\n",
    "\n",
    "print(f\"Train labels: {y_train.sum(axis=1).mean():.2f} categorías/imagen\")\n",
    "print(f\"Test labels: {y_test.sum(axis=1).mean():.2f} categorías/imagen\")\n",
    "print(f\"Val labels: {y_val.sum(axis=1).mean():.2f} categorías/imagen\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8eddf787",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pesos por clase calculados\n",
      "  Min: 1.30\n",
      "  Max: 46.30\n",
      "  Media: 17.92\n",
      "Loss ponderada definida\n"
     ]
    }
   ],
   "source": [
    "# Calcular pesos por clase para combatir desbalance\n",
    "pos_counts = y_train.sum(axis=0)\n",
    "neg_counts = y_train.shape[0] - pos_counts\n",
    "\n",
    "# Peso positivo = negativos / positivos (LIMITADO a max 10)\n",
    "pos_weight = (neg_counts + 1e-6) / (pos_counts + 1e-6)\n",
    "pos_weight = np.clip(pos_weight, 1.0, 10.0)  # Max 10 en vez de 50\n",
    "\n",
    "class_weights = tf.constant(pos_weight, dtype=tf.float32)\n",
    "\n",
    "print(\"Pesos por clase calculados (limitados a max 10)\")\n",
    "print(f\"  Min: {pos_weight.min():.2f}\")\n",
    "print(f\"  Max: {pos_weight.max():.2f}\")\n",
    "print(f\"  Media: {pos_weight.mean():.2f}\")\n",
    "\n",
    "# Focal Loss con class weights (mejor para desbalance)\n",
    "def focal_loss(y_true, y_pred, gamma=2.0, alpha=0.25):\n",
    "    \"\"\"\n",
    "    Focal Loss para multilabel con class weights.\n",
    "    gamma: factor de enfoque (mayor = más peso a ejemplos difíciles)\n",
    "    alpha: balance positivo/negativo base\n",
    "    \"\"\"\n",
    "    y_pred = tf.clip_by_value(y_pred, 1e-7, 1 - 1e-7)\n",
    "    \n",
    "    # Focal Loss componentes\n",
    "    bce = -(y_true * tf.math.log(y_pred) + (1 - y_true) * tf.math.log(1 - y_pred))\n",
    "    \n",
    "    # Modulación focal: (1 - p_t)^gamma\n",
    "    p_t = y_true * y_pred + (1 - y_true) * (1 - y_pred)\n",
    "    focal_weight = tf.pow(1 - p_t, gamma)\n",
    "    \n",
    "    # Aplicar peso focal y class weights\n",
    "    focal_bce = focal_weight * bce\n",
    "    weighted_focal = focal_bce * (y_true * class_weights + (1 - y_true) * 1.0)\n",
    "    \n",
    "    return tf.reduce_mean(weighted_focal)\n",
    "\n",
    "print(\"Focal Loss con class weights definida (gamma=2.0)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7f838d6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generadores de datos creados\n",
      "  Train samples: 1750\n",
      "  Val samples: 375\n",
      "  Test samples: 376\n",
      "  Batch size: 16\n"
     ]
    }
   ],
   "source": [
    "# Data augmentation para training\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rotation_range=25,\n",
    "    width_shift_range=0.15,\n",
    "    height_shift_range=0.15,\n",
    "    shear_range=0.15,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    brightness_range=[0.8, 1.2],\n",
    "    fill_mode='nearest'\n",
    ")\n",
    "\n",
    "# Sin augmentation para val/test (ya están normalizadas)\n",
    "val_datagen = ImageDataGenerator()\n",
    "test_datagen = ImageDataGenerator()\n",
    "\n",
    "# Fit datagen en datos de train\n",
    "train_datagen.fit(X_train)\n",
    "\n",
    "print(\"Generadores de datos creados\")\n",
    "print(f\"  Train samples: {len(X_train)}\")\n",
    "print(f\"  Val samples: {len(X_val)}\")\n",
    "print(f\"  Test samples: {len(X_test)}\")\n",
    "print(f\"  Batch size: {BATCH_SIZE}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "97110162",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modelo creado\n",
      "Total parametros: 4,841,911\n"
     ]
    }
   ],
   "source": [
    "def create_multilabel_model(num_classes, img_size=(224, 224)):\n",
    "    inputs = layers.Input(shape=(*img_size, 3))\n",
    "    base_model = EfficientNetB0(include_top=False, weights='imagenet', input_tensor=inputs)\n",
    "    base_model.trainable = False\n",
    "    x = base_model.output\n",
    "    x = layers.GlobalAveragePooling2D()(x)\n",
    "    x = layers.Dense(512, activation='relu')(x)\n",
    "    x = layers.Dropout(0.5)(x)\n",
    "    x = layers.Dense(256, activation='relu')(x)\n",
    "    x = layers.Dropout(0.3)(x)\n",
    "    outputs = layers.Dense(num_classes, activation='sigmoid')(x)\n",
    "    model = models.Model(inputs=inputs, outputs=outputs)\n",
    "    return model, base_model\n",
    "\n",
    "model, base_model = create_multilabel_model(NUM_CLASSES, IMG_SIZE)\n",
    "print(f\"Modelo creado\")\n",
    "print(f\"Total parametros: {model.count_params():,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88f57405",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modelo compilado - FASE 1: Training inicial\n",
      "Epoch 1/30\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 189ms/step - auc: 0.4832 - loss: 1.3156 - precision: 0.0799 - recall: 0.5050\n",
      "Epoch 1: val_loss improved from None to 1.27778, saving model to c:\\Users\\mlata\\Documents\\iajordy2\\models\\model_phase1_best.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 232ms/step - auc: 0.4993 - loss: 1.3008 - precision: 0.0851 - recall: 0.5094 - val_auc: 0.4982 - val_loss: 1.2778 - val_precision: 0.0962 - val_recall: 0.6740 - learning_rate: 5.0000e-04\n",
      "Epoch 2/30\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 173ms/step - auc: 0.4935 - loss: 1.2929 - precision: 0.0836 - recall: 0.4946\n",
      "Epoch 2: val_loss improved from 1.27778 to 1.26505, saving model to c:\\Users\\mlata\\Documents\\iajordy2\\models\\model_phase1_best.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 201ms/step - auc: 0.4949 - loss: 1.2837 - precision: 0.0808 - recall: 0.4652 - val_auc: 0.4996 - val_loss: 1.2650 - val_precision: 0.1070 - val_recall: 0.6129 - learning_rate: 5.0000e-04\n",
      "Epoch 3/30\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 179ms/step - auc: 0.4844 - loss: 1.2788 - precision: 0.0866 - recall: 0.4849\n",
      "Epoch 3: val_loss improved from 1.26505 to 1.26443, saving model to c:\\Users\\mlata\\Documents\\iajordy2\\models\\model_phase1_best.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 208ms/step - auc: 0.4954 - loss: 1.2774 - precision: 0.0862 - recall: 0.4917 - val_auc: 0.5000 - val_loss: 1.2644 - val_precision: 0.0756 - val_recall: 0.2886 - learning_rate: 5.0000e-04\n",
      "Epoch 4/30\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 178ms/step - auc: 0.5024 - loss: 1.2781 - precision: 0.0792 - recall: 0.4939\n",
      "Epoch 4: val_loss did not improve from 1.26443\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 208ms/step - auc: 0.4956 - loss: 1.2749 - precision: 0.0761 - recall: 0.4899 - val_auc: 0.5000 - val_loss: 1.2650 - val_precision: 0.0549 - val_recall: 0.3497 - learning_rate: 5.0000e-04\n",
      "Epoch 5/30\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 189ms/step - auc: 0.4818 - loss: 1.2662 - precision: 0.0607 - recall: 0.4021\n",
      "Epoch 5: val_loss did not improve from 1.26443\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 217ms/step - auc: 0.4899 - loss: 1.2744 - precision: 0.0616 - recall: 0.4090 - val_auc: 0.5000 - val_loss: 1.2651 - val_precision: 0.0600 - val_recall: 0.4584 - learning_rate: 5.0000e-04\n",
      "Epoch 6/30\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 188ms/step - auc: 0.4868 - loss: 1.2753 - precision: 0.0812 - recall: 0.5923\n",
      "Epoch 6: val_loss did not improve from 1.26443\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 216ms/step - auc: 0.4923 - loss: 1.2745 - precision: 0.0806 - recall: 0.5938 - val_auc: 0.5000 - val_loss: 1.2648 - val_precision: 0.0558 - val_recall: 0.4261 - learning_rate: 5.0000e-04\n",
      "Epoch 7/30\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 176ms/step - auc: 0.4797 - loss: 1.2767 - precision: 0.0634 - recall: 0.4612\n",
      "Epoch 7: val_loss did not improve from 1.26443\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 203ms/step - auc: 0.4809 - loss: 1.2749 - precision: 0.0598 - recall: 0.4345 - val_auc: 0.5000 - val_loss: 1.2651 - val_precision: 0.0562 - val_recall: 0.3939 - learning_rate: 5.0000e-04\n",
      "Epoch 8/30\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 169ms/step - auc: 0.4989 - loss: 1.2801 - precision: 0.0711 - recall: 0.4793\n",
      "Epoch 8: val_loss did not improve from 1.26443\n",
      "\n",
      "Epoch 8: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 195ms/step - auc: 0.4968 - loss: 1.2750 - precision: 0.0744 - recall: 0.4981 - val_auc: 0.5000 - val_loss: 1.2651 - val_precision: 0.0578 - val_recall: 0.4788 - learning_rate: 5.0000e-04\n",
      "Epoch 9/30\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 169ms/step - auc: 0.4987 - loss: 1.2740 - precision: 0.0657 - recall: 0.5101\n",
      "Epoch 9: val_loss did not improve from 1.26443\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 195ms/step - auc: 0.5010 - loss: 1.2743 - precision: 0.0653 - recall: 0.5161 - val_auc: 0.5000 - val_loss: 1.2651 - val_precision: 0.0570 - val_recall: 0.5076 - learning_rate: 2.5000e-04\n",
      "Epoch 10/30\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 171ms/step - auc: 0.5016 - loss: 1.2716 - precision: 0.0645 - recall: 0.5163\n",
      "Epoch 10: val_loss did not improve from 1.26443\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 197ms/step - auc: 0.5002 - loss: 1.2742 - precision: 0.0640 - recall: 0.5012 - val_auc: 0.5000 - val_loss: 1.2650 - val_precision: 0.0578 - val_recall: 0.4788 - learning_rate: 2.5000e-04\n",
      "Epoch 11/30\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 168ms/step - auc: 0.4950 - loss: 1.2770 - precision: 0.0711 - recall: 0.5710\n",
      "Epoch 11: val_loss did not improve from 1.26443\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 194ms/step - auc: 0.4954 - loss: 1.2743 - precision: 0.0675 - recall: 0.5323 - val_auc: 0.5000 - val_loss: 1.2651 - val_precision: 0.0611 - val_recall: 0.4669 - learning_rate: 2.5000e-04\n",
      "Epoch 12/30\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 175ms/step - auc: 0.4892 - loss: 1.2796 - precision: 0.0720 - recall: 0.5686\n",
      "Epoch 12: val_loss did not improve from 1.26443\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 202ms/step - auc: 0.4893 - loss: 1.2743 - precision: 0.0732 - recall: 0.5839 - val_auc: 0.5000 - val_loss: 1.2651 - val_precision: 0.0835 - val_recall: 0.6910 - learning_rate: 2.5000e-04\n",
      "Epoch 13/30\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 171ms/step - auc: 0.4990 - loss: 1.2617 - precision: 0.0672 - recall: 0.5299\n",
      "Epoch 13: val_loss did not improve from 1.26443\n",
      "\n",
      "Epoch 13: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 198ms/step - auc: 0.4970 - loss: 1.2742 - precision: 0.0672 - recall: 0.5238 - val_auc: 0.5000 - val_loss: 1.2651 - val_precision: 0.0553 - val_recall: 0.4228 - learning_rate: 2.5000e-04\n",
      "Epoch 14/30\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 171ms/step - auc: 0.4942 - loss: 1.2754 - precision: 0.0721 - recall: 0.5843\n",
      "Epoch 14: val_loss did not improve from 1.26443\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 197ms/step - auc: 0.4981 - loss: 1.2742 - precision: 0.0722 - recall: 0.5881 - val_auc: 0.5000 - val_loss: 1.2651 - val_precision: 0.0542 - val_recall: 0.4482 - learning_rate: 1.2500e-04\n",
      "Epoch 15/30\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 170ms/step - auc: 0.4985 - loss: 1.2759 - precision: 0.0733 - recall: 0.5811\n",
      "Epoch 15: val_loss did not improve from 1.26443\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 197ms/step - auc: 0.4949 - loss: 1.2743 - precision: 0.0724 - recall: 0.5775 - val_auc: 0.5000 - val_loss: 1.2651 - val_precision: 0.0553 - val_recall: 0.4228 - learning_rate: 1.2500e-04\n",
      "Epoch 15: early stopping\n",
      "Restoring model weights from the end of the best epoch: 3.\n",
      "Fase 1 completada\n"
     ]
    }
   ],
   "source": [
    "model.compile(\n",
    "    optimizer=optimizers.Adam(learning_rate=LEARNING_RATE_INITIAL),\n",
    "    loss=focal_loss,\n",
    "    metrics=[\n",
    "        keras.metrics.Precision(name='precision'),\n",
    "        keras.metrics.Recall(name='recall'),\n",
    "        keras.metrics.AUC(name='auc', multi_label=True)\n",
    "    ]\n",
    ")\n",
    "\n",
    "callbacks = [\n",
    "    keras.callbacks.EarlyStopping(monitor='val_loss', patience=12, restore_best_weights=True, verbose=1),\n",
    "    keras.callbacks.ModelCheckpoint(filepath=str(MODELS_DIR / 'model_phase1_best.h5'), monitor='val_loss', save_best_only=True, verbose=1),\n",
    "    keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=5, min_lr=1e-8, verbose=1)\n",
    "]\n",
    "\n",
    "print(f\"Modelo compilado - FASE 1: Training inicial con Focal Loss\")\n",
    "\n",
    "history_phase1 = model.fit(\n",
    "    train_datagen.flow(X_train, y_train, batch_size=BATCH_SIZE),\n",
    "    epochs=INITIAL_EPOCHS,\n",
    "    validation_data=(X_val, y_val),\n",
    "    callbacks=callbacks,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "print(f\"Fase 1 completada\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a45ad84e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FASE 2: Fine-tuning con ultimas 40 capas descongeladas\n",
      "Epoch 1/40\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 192ms/step - auc: 0.4972 - loss: 1.2751 - precision: 0.0885 - recall: 0.5031\n",
      "Epoch 1: val_loss did not improve from 1.26443\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 233ms/step - auc: 0.5129 - loss: 1.2819 - precision: 0.0882 - recall: 0.5016 - val_auc: 0.5067 - val_loss: 1.2647 - val_precision: 0.1157 - val_recall: 0.5891 - learning_rate: 5.0000e-05\n",
      "Epoch 2/40\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 198ms/step - auc: 0.5013 - loss: 1.2757 - precision: 0.0808 - recall: 0.4591\n",
      "Epoch 2: val_loss did not improve from 1.26443\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 227ms/step - auc: 0.5045 - loss: 1.2798 - precision: 0.0812 - recall: 0.4603 - val_auc: 0.4911 - val_loss: 1.2646 - val_precision: 0.1114 - val_recall: 0.5739 - learning_rate: 5.0000e-05\n",
      "Epoch 3/40\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 206ms/step - auc: 0.5106 - loss: 1.2866 - precision: 0.0862 - recall: 0.4954\n",
      "Epoch 3: val_loss did not improve from 1.26443\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 233ms/step - auc: 0.4951 - loss: 1.2791 - precision: 0.0826 - recall: 0.4832 - val_auc: 0.4997 - val_loss: 1.2647 - val_precision: 0.1076 - val_recall: 0.5569 - learning_rate: 5.0000e-05\n",
      "Epoch 4/40\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 209ms/step - auc: 0.4914 - loss: 1.2843 - precision: 0.0846 - recall: 0.4904\n",
      "Epoch 4: val_loss did not improve from 1.26443\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 236ms/step - auc: 0.4948 - loss: 1.2780 - precision: 0.0821 - recall: 0.4800 - val_auc: 0.4958 - val_loss: 1.2646 - val_precision: 0.1049 - val_recall: 0.6010 - learning_rate: 5.0000e-05\n",
      "Epoch 5/40\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 207ms/step - auc: 0.4788 - loss: 1.2779 - precision: 0.0783 - recall: 0.4657\n",
      "Epoch 5: val_loss did not improve from 1.26443\n",
      "\n",
      "Epoch 5: ReduceLROnPlateau reducing learning rate to 2.499999936844688e-05.\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 234ms/step - auc: 0.4878 - loss: 1.2792 - precision: 0.0808 - recall: 0.4740 - val_auc: 0.4950 - val_loss: 1.2646 - val_precision: 0.0964 - val_recall: 0.6197 - learning_rate: 5.0000e-05\n",
      "Epoch 6/40\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 192ms/step - auc: 0.4824 - loss: 1.2716 - precision: 0.0877 - recall: 0.5005\n",
      "Epoch 6: val_loss did not improve from 1.26443\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 220ms/step - auc: 0.4883 - loss: 1.2781 - precision: 0.0875 - recall: 0.4995 - val_auc: 0.5029 - val_loss: 1.2645 - val_precision: 0.0934 - val_recall: 0.6503 - learning_rate: 2.5000e-05\n",
      "Epoch 7/40\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 194ms/step - auc: 0.4978 - loss: 1.2816 - precision: 0.0849 - recall: 0.4912\n",
      "Epoch 7: val_loss did not improve from 1.26443\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 221ms/step - auc: 0.5095 - loss: 1.2743 - precision: 0.0861 - recall: 0.4924 - val_auc: 0.4843 - val_loss: 1.2649 - val_precision: 0.0889 - val_recall: 0.7368 - learning_rate: 2.5000e-05\n",
      "Epoch 8/40\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 193ms/step - auc: 0.4843 - loss: 1.2750 - precision: 0.0807 - recall: 0.4661\n",
      "Epoch 8: val_loss did not improve from 1.26443\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 220ms/step - auc: 0.4832 - loss: 1.2771 - precision: 0.0806 - recall: 0.4627 - val_auc: 0.4900 - val_loss: 1.2648 - val_precision: 0.0905 - val_recall: 0.7334 - learning_rate: 2.5000e-05\n",
      "Epoch 9/40\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 191ms/step - auc: 0.5038 - loss: 1.2760 - precision: 0.0832 - recall: 0.4609\n",
      "Epoch 9: val_loss did not improve from 1.26443\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 218ms/step - auc: 0.4997 - loss: 1.2757 - precision: 0.0812 - recall: 0.4430 - val_auc: 0.5011 - val_loss: 1.2646 - val_precision: 0.0695 - val_recall: 0.3735 - learning_rate: 2.5000e-05\n",
      "Epoch 10/40\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 193ms/step - auc: 0.5106 - loss: 1.2770 - precision: 0.0781 - recall: 0.4103\n",
      "Epoch 10: val_loss improved from 1.26443 to 1.26417, saving model to c:\\Users\\mlata\\Documents\\iajordy2\\models\\model_phase1_best.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 222ms/step - auc: 0.5046 - loss: 1.2751 - precision: 0.0781 - recall: 0.4097 - val_auc: 0.4968 - val_loss: 1.2642 - val_precision: 0.0601 - val_recall: 0.3735 - learning_rate: 2.5000e-05\n",
      "Epoch 11/40\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 193ms/step - auc: 0.4886 - loss: 1.2616 - precision: 0.0764 - recall: 0.3893\n",
      "Epoch 11: val_loss did not improve from 1.26417\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 221ms/step - auc: 0.4921 - loss: 1.2765 - precision: 0.0762 - recall: 0.3871 - val_auc: 0.5014 - val_loss: 1.2647 - val_precision: 0.0692 - val_recall: 0.3939 - learning_rate: 2.5000e-05\n",
      "Epoch 12/40\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 197ms/step - auc: 0.4779 - loss: 1.2647 - precision: 0.0737 - recall: 0.3932\n",
      "Epoch 12: val_loss did not improve from 1.26417\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 224ms/step - auc: 0.4867 - loss: 1.2767 - precision: 0.0760 - recall: 0.3960 - val_auc: 0.4841 - val_loss: 1.2645 - val_precision: 0.0948 - val_recall: 0.6978 - learning_rate: 2.5000e-05\n",
      "Epoch 13/40\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 202ms/step - auc: 0.4778 - loss: 1.2872 - precision: 0.0767 - recall: 0.4034\n",
      "Epoch 13: val_loss did not improve from 1.26417\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 230ms/step - auc: 0.4878 - loss: 1.2760 - precision: 0.0774 - recall: 0.4037 - val_auc: 0.5020 - val_loss: 1.2649 - val_precision: 0.0909 - val_recall: 0.6655 - learning_rate: 2.5000e-05\n",
      "Epoch 14/40\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 194ms/step - auc: 0.4904 - loss: 1.2679 - precision: 0.0762 - recall: 0.3902\n",
      "Epoch 14: val_loss did not improve from 1.26417\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 222ms/step - auc: 0.4967 - loss: 1.2753 - precision: 0.0785 - recall: 0.4105 - val_auc: 0.4948 - val_loss: 1.2650 - val_precision: 0.0955 - val_recall: 0.6129 - learning_rate: 2.5000e-05\n",
      "Epoch 15/40\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 200ms/step - auc: 0.4857 - loss: 1.2774 - precision: 0.0782 - recall: 0.4055\n",
      "Epoch 15: val_loss did not improve from 1.26417\n",
      "\n",
      "Epoch 15: ReduceLROnPlateau reducing learning rate to 1.249999968422344e-05.\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 227ms/step - auc: 0.4886 - loss: 1.2762 - precision: 0.0797 - recall: 0.4140 - val_auc: 0.4954 - val_loss: 1.2653 - val_precision: 0.0958 - val_recall: 0.4635 - learning_rate: 2.5000e-05\n",
      "Epoch 16/40\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 205ms/step - auc: 0.4971 - loss: 1.2715 - precision: 0.0817 - recall: 0.4139\n",
      "Epoch 16: val_loss did not improve from 1.26417\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 233ms/step - auc: 0.5040 - loss: 1.2746 - precision: 0.0823 - recall: 0.4189 - val_auc: 0.5022 - val_loss: 1.2649 - val_precision: 0.0968 - val_recall: 0.4703 - learning_rate: 1.2500e-05\n",
      "Epoch 17/40\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 207ms/step - auc: 0.5015 - loss: 1.2845 - precision: 0.0801 - recall: 0.4296\n",
      "Epoch 17: val_loss did not improve from 1.26417\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 235ms/step - auc: 0.5032 - loss: 1.2742 - precision: 0.0809 - recall: 0.4327 - val_auc: 0.4970 - val_loss: 1.2647 - val_precision: 0.0922 - val_recall: 0.5161 - learning_rate: 1.2500e-05\n",
      "Epoch 18/40\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 206ms/step - auc: 0.4947 - loss: 1.2853 - precision: 0.0795 - recall: 0.4294\n",
      "Epoch 18: val_loss did not improve from 1.26417\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 234ms/step - auc: 0.5044 - loss: 1.2742 - precision: 0.0790 - recall: 0.4324 - val_auc: 0.4964 - val_loss: 1.2648 - val_precision: 0.0876 - val_recall: 0.5110 - learning_rate: 1.2500e-05\n",
      "Epoch 19/40\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 206ms/step - auc: 0.4979 - loss: 1.2711 - precision: 0.0798 - recall: 0.4410\n",
      "Epoch 19: val_loss did not improve from 1.26417\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 235ms/step - auc: 0.5132 - loss: 1.2740 - precision: 0.0811 - recall: 0.4472 - val_auc: 0.4981 - val_loss: 1.2648 - val_precision: 0.0904 - val_recall: 0.6367 - learning_rate: 1.2500e-05\n",
      "Epoch 20/40\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 198ms/step - auc: 0.4835 - loss: 1.2689 - precision: 0.0805 - recall: 0.4303\n",
      "Epoch 20: val_loss did not improve from 1.26417\n",
      "\n",
      "Epoch 20: ReduceLROnPlateau reducing learning rate to 6.24999984211172e-06.\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 225ms/step - auc: 0.4904 - loss: 1.2755 - precision: 0.0813 - recall: 0.4387 - val_auc: 0.5108 - val_loss: 1.2648 - val_precision: 0.0590 - val_recall: 0.3837 - learning_rate: 1.2500e-05\n",
      "Epoch 21/40\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 192ms/step - auc: 0.4969 - loss: 1.2739 - precision: 0.0836 - recall: 0.4566\n",
      "Epoch 21: val_loss did not improve from 1.26417\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 220ms/step - auc: 0.4983 - loss: 1.2749 - precision: 0.0826 - recall: 0.4497 - val_auc: 0.5033 - val_loss: 1.2648 - val_precision: 0.0594 - val_recall: 0.3871 - learning_rate: 6.2500e-06\n",
      "Epoch 22/40\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 218ms/step - auc: 0.4932 - loss: 1.2692 - precision: 0.0838 - recall: 0.4532\n",
      "Epoch 22: val_loss did not improve from 1.26417\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 247ms/step - auc: 0.5102 - loss: 1.2739 - precision: 0.0844 - recall: 0.4641 - val_auc: 0.4994 - val_loss: 1.2648 - val_precision: 0.0600 - val_recall: 0.3871 - learning_rate: 6.2500e-06\n",
      "Epoch 22: early stopping\n",
      "Restoring model weights from the end of the best epoch: 10.\n",
      "Fase 2 completada\n"
     ]
    }
   ],
   "source": [
    "base_model.trainable = True\n",
    "fine_tune_at = len(base_model.layers) - 40\n",
    "for layer in base_model.layers[:fine_tune_at]:\n",
    "    layer.trainable = False\n",
    "\n",
    "model.compile(\n",
    "    optimizer=optimizers.Adam(learning_rate=LEARNING_RATE_FINETUNING),\n",
    "    loss=focal_loss,\n",
    "    metrics=[\n",
    "        keras.metrics.Precision(name='precision'),\n",
    "        keras.metrics.Recall(name='recall'),\n",
    "        keras.metrics.AUC(name='auc', multi_label=True)\n",
    "    ]\n",
    ")\n",
    "\n",
    "train_datagen_ft = ImageDataGenerator(\n",
    "    rotation_range=25,\n",
    "    width_shift_range=0.15,\n",
    "    height_shift_range=0.15,\n",
    "    shear_range=0.15,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    brightness_range=[0.8, 1.2],\n",
    "    fill_mode='nearest',\n",
    "    vertical_flip=False\n",
    ")\n",
    "\n",
    "print(f\"FASE 2: Fine-tuning con ultimas {len(base_model.layers) - fine_tune_at} capas descongeladas\")\n",
    "\n",
    "history_phase2 = model.fit(\n",
    "    train_datagen_ft.flow(X_train, y_train, batch_size=BATCH_SIZE),\n",
    "    epochs=FINETUNING_EPOCHS,\n",
    "    validation_data=(X_val, y_val),\n",
    "    callbacks=callbacks,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "print(f\"Fase 2 completada\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99776267",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 427ms/step\n",
      "Threshold optimo (global): 0.05\n",
      "F1-micro max (global): 0.1456\n",
      "Thresholds por clase (promedio): 0.07\n",
      "METRICAS FINALES EN VALIDACION\n",
      "hamming_loss: 0.9211\n",
      "subset_accuracy: 0.0000\n",
      "f1_micro: 0.1457\n",
      "f1_macro: 0.1366\n",
      "precision_micro: 0.0786\n",
      "recall_micro: 1.0000\n",
      "Tasa de positivos predichos: 0.9996\n"
     ]
    }
   ],
   "source": [
    "y_val_pred = model.predict(X_val, verbose=1)\n",
    "\n",
    "# Buscar umbral optimo global por F1-micro (rango ajustado 0.2-0.8)\n",
    "thresholds = np.arange(0.2, 0.85, 0.05)\n",
    "f1_scores = []\n",
    "for thresh in thresholds:\n",
    "    y_val_pred_binary = (y_val_pred >= thresh).astype(int)\n",
    "    f1_scores.append(f1_score(y_val, y_val_pred_binary, average='micro'))\n",
    "\n",
    "best_idx = int(np.argmax(f1_scores))\n",
    "best_threshold = float(thresholds[best_idx])\n",
    "print(f\"Threshold optimo (global): {best_threshold:.2f}\")\n",
    "print(f\"F1-micro max (global): {f1_scores[best_idx]:.4f}\")\n",
    "\n",
    "# Umbral optimo por clase\n",
    "best_thresholds = []\n",
    "for c in range(NUM_CLASSES):\n",
    "    f1_c = []\n",
    "    for thresh in thresholds:\n",
    "        pred_c = (y_val_pred[:, c] >= thresh).astype(int)\n",
    "        f1_c.append(f1_score(y_val[:, c], pred_c, average='binary', zero_division=0))\n",
    "    best_thresholds.append(float(thresholds[int(np.argmax(f1_c))]))\n",
    "\n",
    "best_thresholds = np.array(best_thresholds)\n",
    "print(f\"Thresholds por clase (promedio): {best_thresholds.mean():.2f}\")\n",
    "print(f\"Thresholds por clase (min-max): {best_thresholds.min():.2f} - {best_thresholds.max():.2f}\")\n",
    "\n",
    "# Metricas finales con thresholds por clase\n",
    "y_val_pred_binary = (y_val_pred >= best_thresholds).astype(int)\n",
    "positive_rate = y_val_pred_binary.mean()\n",
    "metrics_phase2 = {\n",
    "    'hamming_loss': hamming_loss(y_val, y_val_pred_binary),\n",
    "    'subset_accuracy': accuracy_score(y_val, y_val_pred_binary),\n",
    "    'f1_micro': f1_score(y_val, y_val_pred_binary, average='micro'),\n",
    "    'f1_macro': f1_score(y_val, y_val_pred_binary, average='macro'),\n",
    "    'precision_micro': precision_score(y_val, y_val_pred_binary, average='micro'),\n",
    "    'recall_micro': recall_score(y_val, y_val_pred_binary, average='micro'),\n",
    "}\n",
    "\n",
    "print(\"\\nMETRICAS FINALES EN VALIDACION\")\n",
    "for metric, value in metrics_phase2.items():\n",
    "    print(f\"{metric}: {value:.4f}\")\n",
    "print(f\"Tasa de positivos predichos: {positive_rate:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d3199d0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modelo guardado\n",
      "Resultados guardados\n"
     ]
    }
   ],
   "source": [
    "model.save(MODELS_DIR / 'voc_multilabel_final.h5')\n",
    "model.save(MODELS_DIR / 'voc_multilabel_final.keras')\n",
    "print(f\"Modelo guardado\")\n",
    "\n",
    "with open(MODELS_DIR / 'training_results.json', 'w') as f:\n",
    "    json.dump({\n",
    "        'metrics': metrics_phase2,\n",
    "        'config': {\n",
    "            'initial_epochs': INITIAL_EPOCHS,\n",
    "            'finetuning_epochs': FINETUNING_EPOCHS,\n",
    "            'batch_size': BATCH_SIZE,\n",
    "            'img_size': IMG_SIZE,\n",
    "            'learning_rate_initial': LEARNING_RATE_INITIAL,\n",
    "            'learning_rate_finetuning': LEARNING_RATE_FINETUNING\n",
    "        },\n",
    "        'thresholds': best_thresholds.tolist()\n",
    "    }, f, indent=2)\n",
    "print(f\"Resultados guardados\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
