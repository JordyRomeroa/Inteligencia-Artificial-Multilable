{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "421c5590",
   "metadata": {},
   "source": [
    "# YOLO Model Training Pipeline\n",
    "\n",
    "This notebook executes the complete training workflow for YOLOv8n object detection model using Pascal VOC 2012 dataset. Trains on real-world dataset with configuration defined in notebook 02, tracks metrics with MLflow, and validates trained model.\n",
    "\n",
    "## Training Workflow:\n",
    "1. Load model configuration from notebook 02\n",
    "2. Initialize YOLO model with pretrained COCO weights\n",
    "3. Execute training on Pascal VOC 2012 dataset (3000-5000 filtered images)\n",
    "4. Track training progress and metrics with MLflow\n",
    "5. **Register model in MLflow Model Registry** ‚ú®\n",
    "6. Validate trained model on validation dataset\n",
    "7. Verify best.pt checkpoint ready for prediction phase\n",
    "\n",
    "## Training Duration:\n",
    "- GPU: 30-60 minutes\n",
    "- CPU: 3-4 hours\n",
    "\n",
    "## Dataset: \n",
    "Pascal VOC 2012 (~70% train, 15% val, 15% test split)\n",
    "\n",
    "## MLflow Integration:\n",
    "- **Experiments tab:** M√©tricas, par√°metros, artifacts\n",
    "- **Models tab:** Versiones registradas con staging/producci√≥n üÜï\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86748e55",
   "metadata": {},
   "source": [
    "##  IMPORTANTE: Ruta √önica del Modelo\n",
    "\n",
    "Para evitar confusiones, este notebook usa **UNA SOLA RUTA** para el modelo entrenado:\n",
    "\n",
    "```\n",
    "models/best.pt\n",
    "```\n",
    "\n",
    "**Esta es la √öNICA ubicaci√≥n que importa.** Todas las dem√°s rutas son temporales:\n",
    "- `runs/detect/yolo_run/weights/best.pt` ‚Üí Ruta temporal de YOLO (se copia a models/)\n",
    "- MLflow artifacts ‚Üí Copia autom√°tica para tracking\n",
    "\n",
    "**Para usar el modelo en predicciones/API:**\n",
    "```python\n",
    "from ultralytics import YOLO\n",
    "model = YOLO('models/best.pt')  # ‚Üê SIEMPRE usa esta ruta\n",
    "```\n",
    "\n",
    "**NO uses rutas de `runs/` porque se borran al re-entrenar.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "89c54676",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLflow Configuration\n",
      "============================================================\n",
      "Tracking URI: file:///C:/Users/jordy/OneDrive/Desktop/iaaaa/iajordy2/runs/mlflow\n",
      "Experiment: yolo_3class_detection\n",
      "============================================================\n",
      "\n",
      "YOLO MODEL CONFIGURATION\n",
      "============================================================\n",
      "Project Root: C:\\Users\\jordy\\OneDrive\\Desktop\\iaaaa\\iajordy2\n",
      "Data Dir: C:\\Users\\jordy\\OneDrive\\Desktop\\iaaaa\\iajordy2\\data\n",
      "Models Dir: C:\\Users\\jordy\\OneDrive\\Desktop\\iaaaa\\iajordy2\\models\n",
      "CUDA Available: True\n",
      "GPU: NVIDIA GeForce RTX 3080 Laptop GPU\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "import yaml\n",
    "from pathlib import Path\n",
    "import mlflow\n",
    "import os\n",
    "import torch\n",
    "import shutil\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from ultralytics import YOLO\n",
    "from PIL import Image\n",
    "import sys\n",
    "\n",
    "# Project structure\n",
    "PROJECT_ROOT = Path('../').resolve()\n",
    "DATA_DIR = PROJECT_ROOT / 'data'\n",
    "MODELS_DIR = PROJECT_ROOT / 'models'\n",
    "RUNS_DIR = PROJECT_ROOT / 'runs'\n",
    "MODELS_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Agregar carpeta app al path para importar mlflow_utils\n",
    "sys.path.insert(0, str(PROJECT_ROOT / 'app'))\n",
    "from mlflow_utils import setup_mlflow, MLflowYOLOTracker\n",
    "\n",
    "# Reproducibility\n",
    "SEED = 42\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed(SEED)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "\n",
    "# Configurar MLflow usando funci√≥n helper\n",
    "tracker = setup_mlflow(PROJECT_ROOT)\n",
    "\n",
    "print(\"\\nYOLO MODEL CONFIGURATION\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"Project Root: {PROJECT_ROOT}\")\n",
    "print(f\"Data Dir: {DATA_DIR}\")\n",
    "print(f\"Models Dir: {MODELS_DIR}\")\n",
    "print(f\"CUDA Available: {torch.cuda.is_available()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n",
    "print(\"=\" * 60)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8013f72",
   "metadata": {},
   "source": [
    "Stage 1: Environment Initialization and MLflow Setup\n",
    "\n",
    "This stage sets up the training environment with reproducibility settings and experiment tracking configuration.\n",
    "\n",
    "Components:\n",
    "- PyTorch and NumPy: Deep learning framework and numerical operations\n",
    "- MLflow: Experiment tracking and model versioning\n",
    "- YOLO: Ultralytics YOLOv8 object detection framework\n",
    "\n",
    "Reproducibility:\n",
    "- Fixed seeds (42) for NumPy, PyTorch CPU, and CUDA GPU\n",
    "- Ensures identical results across different runs and machines\n",
    "\n",
    "MLflow configuration:\n",
    "- Sets tracking URI to local mlruns directory\n",
    "- Creates experiment named \"yolo_3class_detection\"\n",
    "- All training metrics will be logged and retrievable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6125e9cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[1] Loading Configuration\n",
      "------------------------------------------------------------\n",
      "Model: yolov8n\n",
      "Classes: 3 (person, car, dog)\n",
      "\n",
      "Training config:\n",
      "  epochs: 50\n",
      "  batch_size: 16\n",
      "  imgsz: 416\n",
      "  patience: 10\n",
      "  device: 0\n",
      "  seed: 42\n",
      "  lr0: 0.01\n",
      "  lrf: 0.01\n",
      "  momentum: 0.937\n",
      "  weight_decay: 0.0005\n",
      "  warmup_epochs: 3.0\n",
      "  warmup_momentum: 0.8\n"
     ]
    }
   ],
   "source": [
    "# Configuration (from notebook 02)\n",
    "MODEL_NAME = 'yolov8n'\n",
    "PRETRAINED_WEIGHTS = 'yolov8n.pt'\n",
    "NUM_CLASSES = 3\n",
    "CLASS_NAMES = ['person', 'car', 'dog']\n",
    "\n",
    "TRAINING_CONFIG = {\n",
    "    'epochs': 50,\n",
    "    'batch_size': 16,\n",
    "    'imgsz': 416,\n",
    "    'patience': 10,\n",
    "    'device': 0 if torch.cuda.is_available() else 'cpu',\n",
    "    'seed': SEED,\n",
    "    'lr0': 0.01,\n",
    "    'lrf': 0.01,\n",
    "    'momentum': 0.937,\n",
    "    'weight_decay': 0.0005,\n",
    "    'warmup_epochs': 3.0,\n",
    "    'warmup_momentum': 0.8,\n",
    "}\n",
    "\n",
    "print(\"\\n[1] Loading Configuration\")\n",
    "print(\"-\" * 60)\n",
    "print(f\"Model: {MODEL_NAME}\")\n",
    "print(f\"Classes: {NUM_CLASSES} ({', '.join(CLASS_NAMES)})\")\n",
    "print(f\"\\nTraining config:\")\n",
    "for key, value in TRAINING_CONFIG.items():\n",
    "    print(f\"  {key}: {value}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c669642",
   "metadata": {},
   "source": [
    "Stage 2: Load Configuration from Notebook 02\n",
    "\n",
    "This stage replicates the model and training configuration defined in notebook 02.\n",
    "\n",
    "Configuration includes:\n",
    "- Model name and pretrained weights\n",
    "- Dataset specification (3 classes)\n",
    "- All training hyperparameters\n",
    "\n",
    "This duplication ensures that notebook 03 is self-contained and can be executed independently after notebook 02."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8a7265d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jordy\\OneDrive\\Desktop\\iaaaa\\iajordy2\\.venv\\lib\\site-packages\\mlflow\\pyfunc\\utils\\data_validation.py:186: UserWarning: \u001b[33mAdd type hints to the `predict` method to enable data validation and automatic signature inference during model logging. Check https://mlflow.org/docs/latest/model/python_model.html#type-hint-usage-in-pythonmodel for more details.\u001b[0m\n",
      "  color_warning(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úì Logged 20 parameters to MLflow\n",
      "\n",
      "[2] Starting Training\n",
      "------------------------------------------------------------\n",
      "New https://pypi.org/project/ultralytics/8.4.12 available  Update with 'pip install -U ultralytics'\n",
      "Ultralytics 8.4.10  Python-3.10.0 torch-2.5.1+cu121 CUDA:0 (NVIDIA GeForce RTX 3080 Laptop GPU, 8192MiB)\n",
      "\u001b[34m\u001b[1mengine\\trainer: \u001b[0magnostic_nms=False, amp=True, angle=1.0, augment=False, auto_augment=randaugment, batch=16, bgr=0.0, box=7.5, cache=False, cfg=None, classes=None, close_mosaic=10, cls=0.5, compile=False, conf=None, copy_paste=0.0, copy_paste_mode=flip, cos_lr=False, cutmix=0.0, data=C:\\Users\\jordy\\OneDrive\\Desktop\\iaaaa\\iajordy2\\data\\data.yaml, degrees=0.0, deterministic=True, device=0, dfl=1.5, dnn=False, dropout=0.0, dynamic=False, embed=None, end2end=None, epochs=50, erasing=0.4, exist_ok=True, fliplr=0.5, flipud=0.0, format=torchscript, fraction=1.0, freeze=None, half=False, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, imgsz=416, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.01, lrf=0.01, mask_ratio=4, max_det=300, mixup=0.0, mode=train, model=yolov8n.pt, momentum=0.937, mosaic=1.0, multi_scale=0.0, name=yolo_run, nbs=64, nms=False, opset=None, optimize=False, optimizer=auto, overlap_mask=True, patience=10, perspective=0.0, plots=True, pose=12.0, pretrained=True, profile=False, project=None, rect=False, resume=False, retina_masks=False, rle=1.0, save=True, save_conf=False, save_crop=False, save_dir=C:\\Users\\jordy\\OneDrive\\Desktop\\iaaaa\\iajordy2\\runs\\detect\\yolo_run, save_frames=False, save_json=False, save_period=-1, save_txt=False, scale=0.5, seed=42, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=detect, time=None, tracker=botsort.yaml, translate=0.1, val=True, verbose=True, vid_stride=1, visualize=False, warmup_bias_lr=0.1, warmup_epochs=3.0, warmup_momentum=0.8, weight_decay=0.0005, workers=8, workspace=None\n",
      "Overriding model.yaml nc=80 with nc=3\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n",
      "  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n",
      "  2                  -1  1      7360  ultralytics.nn.modules.block.C2f             [32, 32, 1, True]             \n",
      "  3                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
      "  4                  -1  2     49664  ultralytics.nn.modules.block.C2f             [64, 64, 2, True]             \n",
      "  5                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
      "  6                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n",
      "  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
      "  8                  -1  1    460288  ultralytics.nn.modules.block.C2f             [256, 256, 1, True]           \n",
      "  9                  -1  1    164608  ultralytics.nn.modules.block.SPPF            [256, 256, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  1    148224  ultralytics.nn.modules.block.C2f             [384, 128, 1]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  1     37248  ultralytics.nn.modules.block.C2f             [192, 64, 1]                  \n",
      " 16                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  1    123648  ultralytics.nn.modules.block.C2f             [192, 128, 1]                 \n",
      " 19                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  1    493056  ultralytics.nn.modules.block.C2f             [384, 256, 1]                 \n",
      " 22        [15, 18, 21]  1    751897  ultralytics.nn.modules.head.Detect           [3, 16, None, [64, 128, 256]] \n",
      "Model summary: 130 layers, 3,011,433 parameters, 3,011,417 gradients, 8.2 GFLOPs\n",
      "\n",
      "Transferred 319/355 items from pretrained weights\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed \n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mFast image access  (ping: 0.00.0 ms, read: 1155.5398.6 MB/s, size: 103.6 KB)\n",
      "\u001b[K\u001b[34m\u001b[1mtrain: \u001b[0mScanning C:\\Users\\jordy\\OneDrive\\Desktop\\iaaaa\\iajordy2\\data\\labels\\train.cache... 2026 images, 0 backgrounds, 0 corrupt: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 2026/2026  0.0s\n",
      "\u001b[34m\u001b[1mval: \u001b[0mFast image access  (ping: 0.00.0 ms, read: 922.6303.3 MB/s, size: 94.1 KB)\n",
      "\u001b[K\u001b[34m\u001b[1mval: \u001b[0mScanning C:\\Users\\jordy\\OneDrive\\Desktop\\iaaaa\\iajordy2\\data\\labels\\val.cache... 434 images, 0 backgrounds, 0 corrupt: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 434/434  0.0s\n",
      "Plotting labels to C:\\Users\\jordy\\OneDrive\\Desktop\\iaaaa\\iajordy2\\runs\\detect\\yolo_run\\labels.jpg... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.001429, momentum=0.9) with parameter groups 57 weight(decay=0.0), 64 weight(decay=0.0005), 63 bias(decay=0.0)\n",
      "\u001b[34m\u001b[1mMLflow: \u001b[0mlogging run_id(5fabef836ad541baad59d462b10e78e2) to file:///C:/Users/jordy/OneDrive/Desktop/iaaaa/iajordy2/runs/mlflow\n",
      "\u001b[34m\u001b[1mMLflow: \u001b[0mdisable with 'yolo settings mlflow=False'\n",
      "WARNING \u001b[34m\u001b[1mMLflow: \u001b[0mFailed to initialize: Changing param values is not allowed. Param with key='classes' was already logged with value='person, car, dog' for run ID='5fabef836ad541baad59d462b10e78e2'. Attempted logging new value 'None'.\n",
      "WARNING \u001b[34m\u001b[1mMLflow: \u001b[0mNot tracking this run\n",
      "Image sizes 416 train, 416 val\n",
      "Using 8 dataloader workers\n",
      "Logging results to \u001b[1mC:\\Users\\jordy\\OneDrive\\Desktop\\iaaaa\\iajordy2\\runs\\detect\\yolo_run\u001b[0m\n",
      "Starting training for 50 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K       1/50     0.971G      1.197      1.868      1.242         70        416: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 127/127 9.8it/s 13.0s<0.2s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 14/14 8.5it/s 1.6s0.1s\n",
      "                   all        434       1040      0.637      0.491      0.541      0.336\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K       2/50      1.02G      1.298      1.529      1.316         47        416: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 127/127 11.2it/s 11.3s0.2s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 14/14 7.8it/s 1.8s0.1s\n",
      "                   all        434       1040      0.548      0.483      0.494      0.277\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K       3/50      1.08G       1.36       1.57      1.362         58        416: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 127/127 11.3it/s 11.2s0.2s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 14/14 8.3it/s 1.7s0.1s\n",
      "                   all        434       1040      0.535      0.508      0.508      0.287\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K       4/50      1.08G      1.393      1.573      1.392         54        416: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 127/127 11.8it/s 10.8s0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 14/14 7.9it/s 1.8s0.1s\n",
      "                   all        434       1040      0.506      0.477      0.486      0.258\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K       5/50      1.08G      1.384      1.489      1.375         53        416: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 127/127 11.6it/s 10.9s0.2s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 14/14 9.0it/s 1.6s0.1s\n",
      "                   all        434       1040      0.652      0.367      0.445      0.255\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K       6/50      1.08G      1.335      1.433      1.354         47        416: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 127/127 11.8it/s 10.7s0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 14/14 8.7it/s 1.6s0.1s\n",
      "                   all        434       1040      0.637      0.452      0.503        0.3\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K       7/50      1.08G      1.341      1.403      1.359         48        416: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 127/127 9.8it/s 13.0s<0.2s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 14/14 7.4it/s 1.9s0.1s\n",
      "                   all        434       1040      0.677      0.505      0.581      0.335\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K       8/50      1.08G      1.303       1.38      1.336         68        416: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 127/127 9.7it/s 13.1s0.1ss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 14/14 7.4it/s 1.9s0.1s\n",
      "                   all        434       1040      0.645      0.473      0.534      0.305\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K       9/50      1.08G      1.279      1.337      1.326         54        416: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 127/127 9.8it/s 13.0s<0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 14/14 7.3it/s 1.9s0.1s\n",
      "                   all        434       1040      0.659       0.53      0.583      0.336\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      10/50      1.08G      1.265      1.318      1.322         45        416: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 127/127 9.5it/s 13.3s<0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 14/14 7.8it/s 1.8s0.1s\n",
      "                   all        434       1040      0.653      0.514      0.561      0.346\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      11/50      1.08G      1.248      1.302      1.308         47        416: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 127/127 9.8it/s 13.0s0.2ss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 14/14 7.1it/s 2.0s0.1s\n",
      "                   all        434       1040      0.676      0.617      0.636      0.397\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      12/50      1.08G      1.226      1.245      1.301         47        416: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 127/127 9.8it/s 12.9s0.1ss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 14/14 7.6it/s 1.8s0.1s\n",
      "                   all        434       1040      0.698      0.512      0.576      0.368\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      13/50      1.08G      1.215      1.215      1.283         58        416: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 127/127 9.8it/s 13.0s<0.2s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 14/14 7.3it/s 1.9s0.1s\n",
      "                   all        434       1040      0.768      0.556      0.646       0.39\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      14/50      1.08G      1.211      1.193      1.287         61        416: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 127/127 9.7it/s 13.0s<0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 14/14 7.6it/s 1.9s0.1s\n",
      "                   all        434       1040      0.713      0.535      0.608      0.374\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      15/50      1.08G      1.187      1.165       1.27         61        416: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 127/127 9.8it/s 13.0s0.2ss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 14/14 7.4it/s 1.9s0.1s\n",
      "                   all        434       1040      0.705      0.557      0.618      0.391\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      16/50      1.08G      1.179       1.18      1.262         47        416: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 127/127 9.8it/s 12.9s0.1ss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 14/14 7.7it/s 1.8s0.1s\n",
      "                   all        434       1040      0.803      0.569      0.677      0.435\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      17/50      1.08G      1.158      1.157      1.264         62        416: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 127/127 9.8it/s 12.9s0.1ss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 14/14 7.4it/s 1.9s0.1s\n",
      "                   all        434       1040      0.663      0.554      0.595      0.368\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      18/50      1.08G      1.151      1.116      1.244         59        416: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 127/127 9.6it/s 13.2s<0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 14/14 7.6it/s 1.9s0.1s\n",
      "                   all        434       1040      0.749       0.58      0.668      0.426\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      19/50      1.08G      1.137      1.095      1.249         51        416: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 127/127 9.7it/s 13.1s0.2ss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 14/14 7.5it/s 1.9s0.1s\n",
      "                   all        434       1040      0.665      0.617      0.635      0.405\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      20/50      1.08G       1.13      1.101       1.24         55        416: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 127/127 9.8it/s 13.0s0.1ss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 14/14 7.7it/s 1.8s0.1s\n",
      "                   all        434       1040      0.739      0.582      0.666      0.443\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      21/50      1.08G       1.14      1.094      1.236         54        416: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 127/127 9.9it/s 12.8s0.2ss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 14/14 7.6it/s 1.8s0.1s\n",
      "                   all        434       1040      0.669      0.609       0.66      0.436\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      22/50      1.08G      1.134      1.076      1.224         32        416: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 127/127 9.8it/s 13.0s<0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 14/14 7.4it/s 1.9s0.1s\n",
      "                   all        434       1040      0.736      0.629        0.7      0.459\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      23/50      1.08G      1.113      1.035      1.212         62        416: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 127/127 9.6it/s 13.2s0.2ss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 14/14 7.5it/s 1.9s0.1s\n",
      "                   all        434       1040      0.721      0.619      0.688      0.451\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      24/50      1.08G      1.101       1.04      1.212         47        416: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 127/127 9.7it/s 13.1s0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 14/14 7.3it/s 1.9s0.1s\n",
      "                   all        434       1040      0.741      0.588      0.676      0.444\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      25/50      1.08G      1.084      1.012      1.204         34        416: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 127/127 9.6it/s 13.3s0.2ss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 14/14 7.2it/s 1.9s0.1s\n",
      "                   all        434       1040      0.734      0.634      0.695      0.452\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      26/50      1.08G      1.085      1.012      1.204         59        416: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 127/127 9.7it/s 13.0s<0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 14/14 7.7it/s 1.8s0.1s\n",
      "                   all        434       1040      0.729       0.64      0.708      0.475\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      27/50      1.08G      1.068     0.9896      1.194         58        416: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 127/127 9.6it/s 13.2s0.2s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 14/14 7.2it/s 2.0s0.2s\n",
      "                   all        434       1040      0.801      0.619       0.72      0.481\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      28/50      1.08G      1.073     0.9767       1.19         86        416: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 127/127 9.8it/s 13.0s<0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 14/14 7.7it/s 1.8s0.1s\n",
      "                   all        434       1040      0.764      0.648      0.708      0.481\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      29/50      1.08G      1.043     0.9426      1.176         39        416: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 127/127 9.6it/s 13.2s0.2s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 14/14 7.4it/s 1.9s0.1s\n",
      "                   all        434       1040      0.698      0.634      0.696      0.469\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      30/50      1.08G       1.02     0.9384      1.169         72        416: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 127/127 9.7it/s 13.1s0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 14/14 7.7it/s 1.8s0.1s\n",
      "                   all        434       1040      0.817      0.607      0.719      0.482\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      31/50      1.08G      1.034     0.9289      1.171         56        416: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 127/127 9.7it/s 13.1s0.2ss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 14/14 7.3it/s 1.9s0.1s\n",
      "                   all        434       1040       0.75      0.647      0.698      0.465\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      32/50      1.08G      1.038     0.9346      1.174         67        416: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 127/127 9.8it/s 13.0s0.1ss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 14/14 7.7it/s 1.8s0.1s\n",
      "                   all        434       1040      0.789      0.653      0.736      0.493\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      33/50      1.08G      1.014     0.9077      1.168         41        416: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 127/127 9.8it/s 13.0s0.2ss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 14/14 7.2it/s 1.9s0.2s\n",
      "                   all        434       1040      0.832      0.606      0.726      0.486\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      34/50      1.08G      1.008     0.9006      1.159         51        416: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 127/127 9.6it/s 13.2s<0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 14/14 7.4it/s 1.9s0.1s\n",
      "                   all        434       1040      0.798      0.627      0.721      0.496\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      35/50      1.08G      1.005     0.8789      1.153         50        416: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 127/127 9.4it/s 13.5s0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 14/14 7.4it/s 1.9s0.1s\n",
      "                   all        434       1040      0.806      0.647       0.75      0.496\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      36/50      1.08G     0.9988     0.8851       1.15         39        416: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 127/127 9.9it/s 12.9s<0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 14/14 7.7it/s 1.8s0.1s\n",
      "                   all        434       1040      0.816      0.641      0.749      0.505\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      37/50      1.08G     0.9863     0.8817      1.147         33        416: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 127/127 9.7it/s 13.1s0.2ss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 14/14 7.3it/s 1.9s0.1s\n",
      "                   all        434       1040       0.82      0.622      0.742      0.511\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      38/50      1.08G     0.9844     0.8598      1.145         30        416: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 127/127 9.7it/s 13.1s<0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 14/14 7.5it/s 1.9s0.1s\n",
      "                   all        434       1040      0.806      0.645      0.742      0.506\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      39/50      1.08G     0.9705     0.8411      1.133         65        416: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 127/127 9.5it/s 13.4s0.2s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 14/14 7.5it/s 1.9s0.1s\n",
      "                   all        434       1040      0.761      0.695      0.743      0.511\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      40/50      1.08G      0.975     0.8332      1.132         56        416: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 127/127 9.6it/s 13.3s0.1ss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 14/14 7.0it/s 2.0s0.2s\n",
      "                   all        434       1040      0.805      0.645      0.757      0.514\n",
      "Closing dataloader mosaic\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      41/50      1.08G     0.9114     0.7379      1.075         17        416: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 127/127 10.1it/s 12.6s.2ss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 14/14 8.0it/s 1.8s0.1s\n",
      "                   all        434       1040      0.793      0.668      0.739      0.494\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      42/50      1.08G     0.8937     0.6988      1.064         24        416: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 127/127 10.0it/s 12.7s.2ss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 14/14 7.5it/s 1.9s0.1s\n",
      "                   all        434       1040       0.78      0.636      0.723      0.482\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      43/50      1.08G     0.8913     0.6824      1.059         22        416: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 127/127 10.1it/s 12.6s.2ss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 14/14 7.8it/s 1.8s0.1s\n",
      "                   all        434       1040      0.785      0.674      0.746      0.508\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      44/50      1.08G     0.8864     0.6592      1.044         49        416: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 127/127 10.2it/s 12.4s0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 14/14 7.5it/s 1.9s0.1s\n",
      "                   all        434       1040      0.806      0.664      0.748      0.512\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      45/50      1.08G     0.8674     0.6413      1.049         33        416: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 127/127 10.7it/s 11.9s0.2s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 14/14 7.9it/s 1.8s0.1s\n",
      "                   all        434       1040      0.808      0.675      0.756      0.524\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      46/50      1.08G     0.8537     0.6316      1.035         15        416: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 127/127 10.6it/s 12.0s0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 14/14 7.4it/s 1.9s0.1s\n",
      "                   all        434       1040      0.806      0.645      0.741      0.519\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      47/50      1.08G     0.8392     0.6205      1.031         28        416: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 127/127 9.1it/s 14.0s0.2ss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 14/14 5.5it/s 2.6s0.2s\n",
      "                   all        434       1040      0.861      0.622      0.747      0.511\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      48/50      1.08G     0.8359     0.6137      1.023         17        416: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 127/127 8.6it/s 14.9s0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 14/14 6.4it/s 2.2s0.2s\n",
      "                   all        434       1040       0.79      0.657      0.751      0.518\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      49/50      1.08G     0.8237     0.5928      1.017         20        416: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 127/127 8.4it/s 15.0s0.2s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 14/14 7.2it/s 1.9s0.1s\n",
      "                   all        434       1040      0.842      0.623      0.753       0.52\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      50/50      1.08G     0.8209      0.585      1.018         25        416: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 127/127 10.2it/s 12.4s0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 14/14 7.5it/s 1.9s0.1s\n",
      "                   all        434       1040      0.798      0.645      0.752       0.52\n",
      "\n",
      "50 epochs completed in 0.215 hours.\n",
      "Optimizer stripped from C:\\Users\\jordy\\OneDrive\\Desktop\\iaaaa\\iajordy2\\runs\\detect\\yolo_run\\weights\\last.pt, 6.2MB\n",
      "Optimizer stripped from C:\\Users\\jordy\\OneDrive\\Desktop\\iaaaa\\iajordy2\\runs\\detect\\yolo_run\\weights\\best.pt, 6.2MB\n",
      "\n",
      "Validating C:\\Users\\jordy\\OneDrive\\Desktop\\iaaaa\\iajordy2\\runs\\detect\\yolo_run\\weights\\best.pt...\n",
      "Ultralytics 8.4.10  Python-3.10.0 torch-2.5.1+cu121 CUDA:0 (NVIDIA GeForce RTX 3080 Laptop GPU, 8192MiB)\n",
      "Model summary (fused): 73 layers, 3,006,233 parameters, 0 gradients, 8.1 GFLOPs\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 14/14 5.3it/s 2.6s0.2s\n",
      "                   all        434       1040      0.808      0.675      0.756      0.524\n",
      "                person        317        712      0.849      0.681      0.794       0.51\n",
      "                   car        113        243      0.825      0.704      0.773      0.557\n",
      "                   dog         64         85      0.751      0.639      0.701      0.506\n",
      "Speed: 0.1ms preprocess, 0.8ms inference, 0.0ms loss, 1.5ms postprocess per image\n",
      "Results saved to \u001b[1mC:\\Users\\jordy\\OneDrive\\Desktop\\iaaaa\\iajordy2\\runs\\detect\\yolo_run\u001b[0m\n",
      "\u001b[34m\u001b[1mMLflow: \u001b[0mresults logged to file:///C:/Users/jordy/OneDrive/Desktop/iaaaa/iajordy2/runs/mlflow\n",
      "\u001b[34m\u001b[1mMLflow: \u001b[0mdisable with 'yolo settings mlflow=False'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026/02/05 18:28:20 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "‚úì Training completed successfully\n",
      "‚úì Logged 7 metrics to MLflow\n",
      "\n",
      "‚úì Final metrics logged:\n",
      "  mAP50: 0.7562\n",
      "  mAP50_95: 0.5244\n",
      "  precision: 0.8084\n",
      "  recall: 0.6745\n",
      "  mAP50_class_0: 0.5101\n",
      "  mAP50_class_1: 0.5574\n",
      "  mAP50_class_2: 0.5058\n",
      "‚úì Model copied to: C:\\Users\\jordy\\OneDrive\\Desktop\\iaaaa\\iajordy2\\models\\best.pt\n",
      "\n",
      "üíæ Registering model in MLflow Model Registry...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jordy\\OneDrive\\Desktop\\iaaaa\\iajordy2\\.venv\\lib\\site-packages\\mlflow\\tracing\\provider.py:757: FutureWarning: Passing a Python object as `python_model` causes it to be serialized using CloudPickle, it requires exercising caution as Python object serialization mechanisms may execute arbitrary code during deserialization.Consider using a file path (str or Path) instead. See https://mlflow.org/docs/latest/ml/model/models-from-code/ for details.\n",
      "  result = f(*args, **kwargs)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d62648b47e3040fea669e85fe838bab2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading artifacts:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Registered model 'yolo_3class_detector' already exists. Creating a new version of this model...\n",
      "Created version '1' of model 'yolo_3class_detector'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úì Model registered in Model Registry: yolo_3class_detector\n",
      "‚úì MLflow run ended with status: FINISHED\n",
      "\n",
      "============================================================\n",
      "TRAINING COMPLETED SUCCESSFULLY\n",
      "============================================================\n",
      "Model path (√öNICA): C:\\Users\\jordy\\OneDrive\\Desktop\\iaaaa\\iajordy2\\models\\best.pt\n",
      "MLflow run ID: 5fabef836ad541baad59d462b10e78e2\n",
      "Registered model: yolo_3class_detector\n",
      "View in MLflow UI: http://localhost:5001\n",
      "  ‚Üí Experiments tab: Ver m√©tricas y artifacts\n",
      "  ‚Üí Models tab: Ver versiones registradas\n",
      "============================================================\n",
      "\n",
      "üí° IMPORTANTE: Usa SIEMPRE esta ruta para el modelo:\n",
      "   C:\\Users\\jordy\\OneDrive\\Desktop\\iaaaa\\iajordy2\\models\\best.pt\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from mlflow.tracking import MlflowClient\n",
    "import mlflow.pyfunc\n",
    "\n",
    "# Wrapper personalizado para modelo YOLO en MLflow\n",
    "class YOLOWrapper(mlflow.pyfunc.PythonModel):\n",
    "    \"\"\"Wrapper para hacer modelos YOLO compatibles con MLflow Model Registry\"\"\"\n",
    "    \n",
    "    def load_context(self, context):\n",
    "        \"\"\"Carga el modelo YOLO desde artifacts\"\"\"\n",
    "        from ultralytics import YOLO\n",
    "        model_path = context.artifacts[\"model\"]\n",
    "        self.model = YOLO(model_path)\n",
    "    \n",
    "    def predict(self, context, model_input):\n",
    "        \"\"\"Ejecuta predicci√≥n con el modelo YOLO\"\"\"\n",
    "        return self.model.predict(model_input)\n",
    "\n",
    "# Iniciar run de MLflow con tags descriptivos\n",
    "tracker.start_run(\n",
    "    run_name='yolo_training_initial',\n",
    "    tags={\n",
    "        'model_type': MODEL_NAME,\n",
    "        'dataset': 'pascal_voc_2012',\n",
    "        'training_phase': 'initial',\n",
    "        'gpu': torch.cuda.get_device_name(0) if torch.cuda.is_available() else 'cpu'\n",
    "    }\n",
    ")\n",
    "\n",
    "# Loguear par√°metros de forma estructurada\n",
    "tracker.log_training_params(\n",
    "    model_name=MODEL_NAME,\n",
    "    num_classes=NUM_CLASSES,\n",
    "    class_names=CLASS_NAMES,\n",
    "    config=TRAINING_CONFIG,\n",
    "    dataset_info={\n",
    "        'source': 'Pascal VOC 2012',\n",
    "        'classes': NUM_CLASSES,\n",
    "        'train_split': '~70%',\n",
    "        'val_split': '~15%',\n",
    "        'test_split': '~15%'\n",
    "    },\n",
    ")\n",
    "\n",
    "print(\"\\n[2] Starting Training\")\n",
    "print(\"-\" * 60)\n",
    "\n",
    "# Inicializar modelo\n",
    "model = YOLO(PRETRAINED_WEIGHTS)\n",
    "\n",
    "try:\n",
    "    results = model.train(\n",
    "        data=str(DATA_DIR / 'data.yaml'),\n",
    "        epochs=TRAINING_CONFIG['epochs'],\n",
    "        imgsz=TRAINING_CONFIG['imgsz'],\n",
    "        batch=TRAINING_CONFIG['batch_size'],\n",
    "        device=TRAINING_CONFIG['device'],\n",
    "        patience=TRAINING_CONFIG['patience'],\n",
    "        seed=TRAINING_CONFIG['seed'],\n",
    "        save=True,\n",
    "        exist_ok=True,\n",
    "        name='yolo_run',\n",
    "        verbose=True\n",
    "    )\n",
    "    \n",
    "    print(\"\\n‚úì Training completed successfully\")\n",
    "    \n",
    "    # RUTA √öNICA DEL MODELO (sin confusiones)\n",
    "    yolo_run_dir = RUNS_DIR / 'detect' / 'yolo_run'\n",
    "    best_model_path = yolo_run_dir / 'weights' / 'best.pt'\n",
    "    \n",
    "    if best_model_path.exists():\n",
    "        # 1. Loguear m√©tricas finales\n",
    "        if results:\n",
    "            metrics = tracker.log_metrics_from_yolo(results)\n",
    "            print(f\"\\n‚úì Final metrics logged:\")\n",
    "            for key, value in metrics.items():\n",
    "                print(f\"  {key}: {value:.4f}\")\n",
    "        \n",
    "        # 2. Loguear gr√°ficas y configs como artifacts\n",
    "        plots_to_log = ['results.png', 'confusion_matrix.png', 'F1_curve.png']\n",
    "        for plot_file in plots_to_log:\n",
    "            plot_path = yolo_run_dir / plot_file\n",
    "            if plot_path.exists():\n",
    "                mlflow.log_artifact(str(plot_path), artifact_path='plots')\n",
    "        \n",
    "        args_yaml = yolo_run_dir / 'args.yaml'\n",
    "        if args_yaml.exists():\n",
    "            mlflow.log_artifact(str(args_yaml), artifact_path='config')\n",
    "        \n",
    "        # 3. Loguear modelo como artifact simple (para backup)\n",
    "        mlflow.log_artifact(str(best_model_path), artifact_path='model')\n",
    "        \n",
    "        # 4. COPIAR modelo a MODELS_DIR (RUTA √öNICA para uso posterior)\n",
    "        model_final_path = MODELS_DIR / 'best.pt'\n",
    "        shutil.copy2(str(best_model_path), str(model_final_path))\n",
    "        print(f\"‚úì Model copied to: {model_final_path}\")\n",
    "        \n",
    "        # 5. REGISTRAR MODELO EN MODEL REGISTRY (formato MLflow)\n",
    "        print(\"\\nüíæ Registering model in MLflow Model Registry...\")\n",
    "        \n",
    "        # Crear conda environment para reproducibilidad\n",
    "        conda_env = {\n",
    "            'channels': ['defaults'],\n",
    "            'dependencies': [\n",
    "                f'python={sys.version_info.major}.{sys.version_info.minor}.{sys.version_info.micro}',\n",
    "                'pip',\n",
    "                {\n",
    "                    'pip': [\n",
    "                        f'ultralytics=={__import__(\"ultralytics\").__version__}',\n",
    "                        f'torch=={torch.__version__}',\n",
    "                        f'numpy=={np.__version__}',\n",
    "                    ]\n",
    "                }\n",
    "            ],\n",
    "            'name': 'yolo_env'\n",
    "        }\n",
    "        \n",
    "        # Guardar modelo en formato MLflow con wrapper\n",
    "        artifacts = {\"model\": str(best_model_path)}\n",
    "        \n",
    "        mlflow.pyfunc.log_model(\n",
    "            artifact_path=\"yolo_model\",\n",
    "            python_model=YOLOWrapper(),\n",
    "            artifacts=artifacts,\n",
    "            conda_env=conda_env,\n",
    "            registered_model_name='yolo_3class_detector'\n",
    "        )\n",
    "        \n",
    "        print(\"‚úì Model registered in Model Registry: yolo_3class_detector\")\n",
    "        \n",
    "        # 6. Loguear tags y m√©tricas de √©xito\n",
    "        mlflow.set_tag('model_path', str(model_final_path))\n",
    "        mlflow.log_metric('training_success', 1)\n",
    "        tracker.end_run(status='FINISHED')\n",
    "        \n",
    "        print(f\"\\n\" + \"=\"*60)\n",
    "        print(\"TRAINING COMPLETED SUCCESSFULLY\")\n",
    "        print(\"=\"*60)\n",
    "        print(f\"Model path (√öNICA): {model_final_path}\")\n",
    "        print(f\"MLflow run ID: {tracker.run_id}\")\n",
    "        print(f\"Registered model: yolo_3class_detector\")\n",
    "        print(f\"View in MLflow UI: http://localhost:5001\")\n",
    "        print(f\"  ‚Üí Experiments tab: Ver m√©tricas y artifacts\")\n",
    "        print(f\"  ‚Üí Models tab: Ver versiones registradas\")\n",
    "        print(\"=\"*60)\n",
    "        print(f\"\\n IMPORTANTE: Usa SIEMPRE esta ruta para el modelo:\")\n",
    "        print(f\"   {model_final_path}\")\n",
    "        print(\"=\"*60)\n",
    "        \n",
    "    else:\n",
    "        mlflow.log_metric('training_success', 0)\n",
    "        tracker.end_run(status='FAILED')\n",
    "        print(f\"\\n‚úó Training failed - best.pt not found at {best_model_path}\")\n",
    "        \n",
    "except Exception as e:\n",
    "    print(f\"\\n‚úó Training failed with error: {e}\")\n",
    "    mlflow.log_metric('training_success', 0)\n",
    "    mlflow.log_param('error_message', str(e))\n",
    "    tracker.end_run(status='FAILED')\n",
    "    raise\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ebc8d74",
   "metadata": {},
   "source": [
    "Stage 3: Execute Training with Professional MLflow Integration\n",
    "\n",
    "This stage implements production-grade MLflow tracking using modular utilities.\n",
    "\n",
    "## Key Improvements:\n",
    "\n",
    "### 1. **Structured Logging** \n",
    "- Uses `MLflowYOLOTracker` class for consistent logging\n",
    "- Separates params, metrics, and artifacts clearly\n",
    "- Adds descriptive tags for easy experiment filtering\n",
    "\n",
    "### 2. **Artifact Management**\n",
    "- Automatically logs training plots (results.png, confusion_matrix.png, etc.)\n",
    "- Logs model weights with proper organization\n",
    "- Logs training configuration for reproducibility\n",
    "\n",
    "### 3. **Model Versioning** \n",
    "- Semantic versioning (v1.0.0, v1.1.0, etc.)\n",
    "- Metadata file with training details\n",
    "- Differentiates between training and retraining\n",
    "\n",
    "### 4. **Error Handling** \n",
    "- Try-catch for robust error capture\n",
    "- Status logging (FINISHED/FAILED)\n",
    "- Error messages logged to MLflow\n",
    "\n",
    "### 5. **No YOLO MLflow Conflict** \n",
    "- **CRITICAL FIX**: Removed `mlflow=False` parameter\n",
    "- YOLO Ultralytics doesn't have built-in MLflow support\n",
    "- We handle ALL logging manually with our tracker\n",
    "\n",
    "## What Gets Logged:\n",
    "\n",
    "**Parameters:**\n",
    "- Model configuration (epochs, batch_size, lr, etc.)\n",
    "- Dataset information (source, splits, classes)\n",
    "- System info (GPU, device)\n",
    "\n",
    "**Metrics:**\n",
    "- mAP50, mAP50-95 (mean Average Precision)\n",
    "- Precision, Recall (per class and overall)\n",
    "- Class-specific metrics\n",
    "\n",
    "**Artifacts:**\n",
    "- best.pt model file\n",
    "- Training plots (loss curves, metrics, confusion matrix)\n",
    "- Configuration YAML\n",
    "- Model version metadata JSON\n",
    "\n",
    "**Tags:**\n",
    "- model_type, dataset, training_phase\n",
    "- gpu, timestamp\n",
    "- Custom tags for filtering\n",
    "\n",
    "## Benefits:\n",
    "\n",
    " **Reproducibility**: All parameters and configs logged  \n",
    " **Comparison**: Easy to compare runs in MLflow UI  \n",
    " **Debugging**: Plots and logs available for analysis  \n",
    " **Deployment**: Model artifacts ready for production  \n",
    " **Audit Trail**: Complete history of experiments  \n",
    "\n",
    "View results at: http://localhost:5001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6de2d767",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úì Logged 8 parameters to MLflow\n",
      "\n",
      "[3] Running Validation\n",
      "------------------------------------------------------------\n",
      "Loading model from: C:\\Users\\jordy\\OneDrive\\Desktop\\iaaaa\\iajordy2\\models\\best.pt\n",
      "Ultralytics 8.4.10  Python-3.10.0 torch-2.5.1+cu121 CUDA:0 (NVIDIA GeForce RTX 3080 Laptop GPU, 8192MiB)\n",
      "Model summary (fused): 73 layers, 3,006,233 parameters, 0 gradients, 8.1 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mFast image access  (ping: 0.00.0 ms, read: 747.1128.9 MB/s, size: 83.5 KB)\n",
      "\u001b[K\u001b[34m\u001b[1mval: \u001b[0mScanning C:\\Users\\jordy\\OneDrive\\Desktop\\iaaaa\\iajordy2\\data\\labels\\val.cache... 434 images, 0 backgrounds, 0 corrupt: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 434/434  0.0s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 28/28 10.3it/s 2.7s0.1s\n",
      "                   all        434       1040      0.861      0.646      0.759      0.527\n",
      "Speed: 0.6ms preprocess, 1.9ms inference, 0.0ms loss, 0.9ms postprocess per image\n",
      "Results saved to \u001b[1mC:\\Users\\jordy\\OneDrive\\Desktop\\iaaaa\\iajordy2\\runs\\detect\\val2\u001b[0m\n",
      "‚úì Logged 7 metrics to MLflow\n",
      "\n",
      "‚úì Validation Metrics:\n",
      "  mAP50: 0.7587\n",
      "  mAP50_95: 0.5269\n",
      "  precision: 0.8610\n",
      "  recall: 0.6457\n",
      "  mAP50_class_0: 0.5136\n",
      "  mAP50_class_1: 0.5560\n",
      "  mAP50_class_2: 0.5111\n",
      "‚úì MLflow run ended with status: FINISHED\n",
      "\n",
      "‚úì Validation completed and logged to MLflow\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# RUTA √öNICA DEL MODELO ENTRENADO\n",
    "best_model_path = MODELS_DIR / 'best.pt'\n",
    "\n",
    "if best_model_path.exists():\n",
    "    # Iniciar run de validaci√≥n\n",
    "    tracker.start_run(\n",
    "        run_name='yolo_validation_initial',\n",
    "        tags={\n",
    "            'model_type': MODEL_NAME,\n",
    "            'validation_phase': 'post_training',\n",
    "            'model_checkpoint': 'best.pt'\n",
    "        }\n",
    "    )\n",
    "    \n",
    "    # Loguear par√°metros de validaci√≥n\n",
    "    tracker.log_training_params(\n",
    "        model_name=MODEL_NAME,\n",
    "        num_classes=NUM_CLASSES,\n",
    "        class_names=CLASS_NAMES,\n",
    "        config={\n",
    "            'imgsz': TRAINING_CONFIG['imgsz'],\n",
    "            'batch': TRAINING_CONFIG['batch_size'],\n",
    "            'device': TRAINING_CONFIG['device']\n",
    "        },\n",
    "        dataset_info={\n",
    "            'split': 'validation',\n",
    "            'source': 'Pascal VOC 2012'\n",
    "        }\n",
    "    )\n",
    "    \n",
    "    print(\"\\n[3] Running Validation\")\n",
    "    print(\"-\" * 60)\n",
    "    print(f\"Loading model from: {best_model_path}\")\n",
    "    \n",
    "    # Cargar y validar modelo\n",
    "    best_model = YOLO(str(best_model_path))\n",
    "    val_results = best_model.val(\n",
    "        data=str(DATA_DIR / 'data.yaml'),\n",
    "        imgsz=TRAINING_CONFIG['imgsz'],\n",
    "        batch=TRAINING_CONFIG['batch_size'],\n",
    "        device=TRAINING_CONFIG['device'],\n",
    "        verbose=False\n",
    "    )\n",
    "    \n",
    "    # Loguear m√©tricas usando tracker\n",
    "    metrics = tracker.log_metrics_from_yolo(val_results)\n",
    "    \n",
    "    if metrics:\n",
    "        print(\"\\n‚úì Validation Metrics:\")\n",
    "        for metric_name, metric_value in metrics.items():\n",
    "            print(f\"  {metric_name}: {metric_value:.4f}\")\n",
    "    \n",
    "    tracker.end_run(status='FINISHED')\n",
    "    print(\"\\n‚úì Validation completed and logged to MLflow\")\n",
    "    \n",
    "else:\n",
    "    print(f\"\\n‚úó Cannot validate: Model not found at {best_model_path}\")\n",
    "    print(\"   Run the training cell first!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6ee5408",
   "metadata": {},
   "source": [
    "Stage 4: Model Validation and Metrics Logging\n",
    "\n",
    "This stage validates the trained model on the validation dataset and logs performance metrics to MLflow.\n",
    "\n",
    "Validation process:\n",
    "1. Load best.pt model checkpoint\n",
    "2. Execute model.val() on validation dataset with same hyperparameters used in training\n",
    "3. Extract performance metrics from validation results\n",
    "\n",
    "Metrics computed:\n",
    "- mAP50: Mean Average Precision at IoU threshold 0.50\n",
    "- mAP50_95: Mean Average Precision averaged over IoU thresholds 0.50-0.95\n",
    "- precision: Proportion of detections that are correct\n",
    "- recall: Proportion of ground truth objects that are detected\n",
    "\n",
    "MLflow logs:\n",
    "- All metrics for experiment tracking and comparison\n",
    "- Model checkpoint path reference\n",
    "- Validation dataset specification"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9d49d39",
   "metadata": {},
   "source": [
    "## Bonus: Comparing Experiments with MLflow\n",
    "\n",
    "The new MLflow integration allows easy comparison of training runs.\n",
    "This helps select the best model for production deployment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0c09d273",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " COMPARISON OF RECENT RUNS\n",
      "================================================================================\n",
      "                          run_id               runName train_epochs\n",
      "5fabef836ad541baad59d462b10e78e2 yolo_training_initial           50\n",
      "f5a4eb4955db476895ca57205ac641a8 yolo_training_initial           50\n",
      "\n",
      "================================================================================\n",
      " TIP: View detailed comparison in MLflow UI at http://localhost:5001\n",
      "   Select runs ‚Üí Compare ‚Üí View metrics side-by-side\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# COMPARE MULTIPLE TRAINING RUNS (OPTIONAL)\n",
    "# ============================================================================\n",
    "\n",
    "# Ejemplo: Comparar los √∫ltimos 3 runs\n",
    "import mlflow\n",
    "import pandas as pd\n",
    "\n",
    "experiment = mlflow.get_experiment_by_name('yolo_3class_detection')\n",
    "if experiment:\n",
    "    # Obtener √∫ltimos runs\n",
    "    runs = mlflow.search_runs(\n",
    "        experiment_ids=[experiment.experiment_id],\n",
    "        order_by=[\"start_time DESC\"],\n",
    "        max_results=3\n",
    "    )\n",
    "    \n",
    "    if len(runs) > 0:\n",
    "        print(\"\\n COMPARISON OF RECENT RUNS\")\n",
    "        print(\"=\" * 80)\n",
    "        \n",
    "        # Seleccionar columnas relevantes\n",
    "        comparison_cols = [\n",
    "            'run_id', \n",
    "            'tags.mlflow.runName',\n",
    "            'metrics.mAP50',\n",
    "            'metrics.mAP50_95',\n",
    "            'metrics.precision',\n",
    "            'metrics.recall',\n",
    "            'params.train_epochs',\n",
    "            'params.model_version'\n",
    "        ]\n",
    "        \n",
    "        # Filtrar columnas existentes\n",
    "        available_cols = [col for col in comparison_cols if col in runs.columns]\n",
    "        comparison_df = runs[available_cols]\n",
    "        \n",
    "        # Renombrar para claridad\n",
    "        comparison_df.columns = [col.split('.')[-1] for col in comparison_df.columns]\n",
    "        \n",
    "        print(comparison_df.to_string(index=False))\n",
    "        print(\"\\n\" + \"=\" * 80)\n",
    "        print(\" TIP: View detailed comparison in MLflow UI at http://localhost:5001\")\n",
    "        print(\"   Select runs ‚Üí Compare ‚Üí View metrics side-by-side\")\n",
    "    else:\n",
    "        print(\"No runs found yet. Train the model first!\")\n",
    "else:\n",
    "    print(\"Experiment not found. Train the model first!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7980551a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " VERIFICACI√ìN DEL MODELO\n",
      "================================================================================\n",
      "\n",
      " Modelo local encontrado:\n",
      "    Ruta: C:\\Users\\jordy\\OneDrive\\Desktop\\iaaaa\\iajordy2\\models\\best.pt\n",
      "    Tama√±o: 5.92 MB\n",
      "\n",
      " Modelo en Model Registry:\n",
      "     Nombre: yolo_3class_detector\n",
      "    Versiones: 1\n",
      "\n",
      "    √öltima versi√≥n:\n",
      "      Versi√≥n: 1\n",
      "      Stage: None\n",
      "      Run ID: 1504bddfeae34f428ce72e7a605d5486\n",
      "      Creada: 1770334106825\n",
      "\n",
      " C√ìMO USAR EL MODELO:\n",
      "   ============================================================================\n",
      "   # Opci√≥n 1: Desde archivo local (RECOMENDADO)\n",
      "   from ultralytics import YOLO\n",
      "   model = YOLO('models/best.pt')\n",
      "   results = model.predict('imagen.jpg')\n",
      "   \n",
      "   # Opci√≥n 2: Desde MLflow Model Registry\n",
      "   import mlflow\n",
      "   model_uri = 'models:/yolo_3class_detector/latest'\n",
      "   loaded_model = mlflow.pyfunc.load_model(model_uri)\n",
      "   ============================================================================\n",
      "\n",
      " Ver en MLflow UI: http://localhost:5001\n",
      "   ‚Üí Pesta√±a 'Models' ‚Üí 'yolo_3class_detector'\n",
      "   ‚Üí Pesta√±a 'Experiments' ‚Üí 'yolo_3class_detection'\n",
      "\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# VERIFICAR MODELO EN MLFLOW MODEL REGISTRY\n",
    "# ============================================================================\n",
    "import mlflow\n",
    "from mlflow.tracking import MlflowClient\n",
    "from pathlib import Path\n",
    "\n",
    "client = MlflowClient()\n",
    "model_name = 'yolo_3class_detector'\n",
    "\n",
    "print(\"\\n VERIFICACI√ìN DEL MODELO\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# 1. Verificar archivo local\n",
    "PROJECT_ROOT = Path('../').resolve()\n",
    "local_model_path = PROJECT_ROOT / 'models' / 'best.pt'\n",
    "\n",
    "if local_model_path.exists():\n",
    "    size_mb = local_model_path.stat().st_size / (1024 * 1024)\n",
    "    print(f\"\\n Modelo local encontrado:\")\n",
    "    print(f\"    Ruta: {local_model_path}\")\n",
    "    print(f\"    Tama√±o: {size_mb:.2f} MB\")\n",
    "else:\n",
    "    print(f\"\\n Modelo local NO encontrado en: {local_model_path}\")\n",
    "\n",
    "# 2. Verificar Model Registry\n",
    "try:\n",
    "    registered_model = client.get_registered_model(model_name)\n",
    "    versions = client.search_model_versions(f\"name='{model_name}'\")\n",
    "    \n",
    "    print(f\"\\n Modelo en Model Registry:\")\n",
    "    print(f\"     Nombre: {model_name}\")\n",
    "    print(f\"    Versiones: {len(versions)}\")\n",
    "    \n",
    "    if versions:\n",
    "        latest_version = versions[0]\n",
    "        print(f\"\\n    √öltima versi√≥n:\")\n",
    "        print(f\"      Versi√≥n: {latest_version.version}\")\n",
    "        print(f\"      Stage: {latest_version.current_stage}\")\n",
    "        print(f\"      Run ID: {latest_version.run_id}\")\n",
    "        print(f\"      Creada: {latest_version.creation_timestamp}\")\n",
    "        \n",
    "except Exception as e:\n",
    "    print(f\"\\n jecuta la celda de entrenamiento primero\")\n",
    "    print(f\"   Error: {e}\")\n",
    "\n",
    "# 3. Instrucciones de uso\n",
    "print(f\"\\n C√ìMO USAR EL MODELO:\")\n",
    "print(f\"   \" + \"=\"*76)\n",
    "print(f\"   # Opci√≥n 1: Desde archivo local (RECOMENDADO)\")\n",
    "print(f\"   from ultralytics import YOLO\")\n",
    "print(f\"   model = YOLO('models/best.pt')\")\n",
    "print(f\"   results = model.predict('imagen.jpg')\")\n",
    "print(f\"   \")\n",
    "print(f\"   # Opci√≥n 2: Desde MLflow Model Registry\")\n",
    "print(f\"   import mlflow\")\n",
    "print(f\"   model_uri = 'models:/{model_name}/latest'\")\n",
    "print(f\"   loaded_model = mlflow.pyfunc.load_model(model_uri)\")\n",
    "print(f\"   \" + \"=\"*76)\n",
    "\n",
    "print(f\"\\n Ver en MLflow UI: http://localhost:5001\")\n",
    "print(f\"   ‚Üí Pesta√±a 'Models' ‚Üí '{model_name}'\")\n",
    "print(f\"   ‚Üí Pesta√±a 'Experiments' ‚Üí 'yolo_3class_detection'\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77790cc9",
   "metadata": {},
   "source": [
    "##  Verificar Modelo en MLflow\n",
    "\n",
    "Ejecuta la celda siguiente para verificar que el modelo est√° correctamente guardado en:\n",
    "\n",
    "1. ** Local:** `models/best.pt` \n",
    "2. ** MLflow Artifacts:** Como artifact del run\n",
    "3. ** Model Registry:** En la pesta√±a \"Models\" de MLflow UI\n",
    "\n",
    "El modelo ahora aparecer√° en **\"Models\" ‚Üí \"yolo_3class_detector\"** con versionado autom√°tico.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
